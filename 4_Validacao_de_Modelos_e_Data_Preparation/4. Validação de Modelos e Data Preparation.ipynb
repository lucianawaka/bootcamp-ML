{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bootcamp de Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Validação de modelos e Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir o processo de Data Preparation como o fluxo de transformação de dados brutos em dados finais mais apropriados para a criação de modelos de Machine Learning. Algumas tarefas comuns neste processo envolvem, limpeza de dados, seleção de features, transformação de dados, criação de variáveis, etc. \n",
    "\n",
    "Grande parte do trabalho do Cientista de Dados reside em criar boas variáveis e assegurar a qualidade dos dados.\n",
    "\n",
    "\n",
    "**Etapas do processo de Data Preparation**\n",
    "\n",
    "* Data Cleaning\n",
    "    * Identificação de redundâncias e inconsistências\n",
    "        * Exemplos: Valor monetário negativo (pode ou não fazer sentido a depender do contexto); Idade acima de 300 anos ou idade negativa, dentre outros exemplos.\n",
    "    * Identificação/tratamento de outliers\n",
    "        * Exemplos: cliente com 190 anos de idade\n",
    "    * Identificação/tratamento de missing (marcação e imputação)\n",
    "    \n",
    "* Feature Selection\n",
    "    * Como selecionar as melhores features no conjunto de 100, 500, 1000, ou 10000 features? \n",
    "    * Quais questõs poderíamos pensar de um modelo com muitas variáveis?\n",
    "    \n",
    "* Data Transforms\n",
    "    * Discretization Transform\n",
    "        * Encode de uma variável numérica em uma variável ordinal\n",
    "    * Ordinal Transform\n",
    "        * Encode de uma variável categórica em uma variável int\n",
    "    * One Hot Transform\n",
    "        * Encode de uma variável categórica em variável binária\n",
    "    * Normalization Transform\n",
    "        * Altera a escala da variável para um range entre 0 e 1\n",
    "    * Standardization Transform\n",
    "        * Distribuição Normal padrão\n",
    "    * Power Transform\n",
    "        * Altera a distribuição de uma variável de modo a aproximar para uma normal\n",
    "        \n",
    "* Feature Engineering\n",
    "    * Adicionar variáveis externas\n",
    "        * Exemplo: inserir variáveis macroeconômicas, sócioeconômicas, etc.\n",
    "    * Adicionar novas variáveis a partir da dimensão temporal\n",
    "    * Adicionar flag\n",
    "    * Aplicar transformações (mínimo, máximo, média, mediana, desvio padrão, amplitude, etc.)\n",
    "    * Indicadores\n",
    "\n",
    "* Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, podemos resumir:\n",
    "\n",
    "* Alterar a escala da variável: RobustScaler, StandardScaler, MinMaxScaler.\n",
    "* Alterar a distribuição: Power Transform, Quantile Transform, Discretization\n",
    "* Encode de variável categórica\n",
    "    * Nominal: One Hot Encode\n",
    "    * Ordinal: Label Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipos de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis podem ser mensuradas em quatro escalas distintas. As variáveis quantitativas podem ser classificadas em discretas ou contínuas, enquanto que as variáveis qualitativas podem ser agrupadas em nominais ou ordinais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Variáveis qualitativas\n",
    "* variável nominal: não há qualquer ordenação na distribuição dos dados (ou dentre as categorias).\n",
    "    * Exemplos: gênero, cor dos olhos,região de procedência, etc.\n",
    "* variável ordinal: há uma ordem dentre as categorias (escala ordinal).\n",
    "    * Exemplos: escolaridade/grau de instrução, hierarquia militar, estágio de uma doença, mês de observação, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Variáveis quantitativas\n",
    "* variável discreta: seus valores podem ser oriundos de um conjunto finito ou enumerável (contagem).\n",
    "    * Exemplos: número de filhos, número de refeições em um dia, etc.\n",
    "* variável contínua: seus valores pertencem a um intervalo (mensuração).\n",
    "    * Exemplos: temperatura, preço de uma ação, altura, peso, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis quantitativas\n",
    "\n",
    "MinMaxScaler\n",
    "* O range de valores é alterado para $[0,1]$\n",
    "* A distribuição dos dados não se altera\n",
    "* Técnica sensível à outliers\n",
    "\n",
    "Fórmula de cálculo:\n",
    "\n",
    "$$X_{\\text{new}} = \\dfrac{X_i-\\text{min}(X)}{\\text{max}(X)-\\text{min}(X)}$$\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/416/1*vEqbUwYneOkRQXCdPU0n9g.png\" height=200 width=200/>\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)\n",
    "\n",
    "\n",
    "MaxAbsScaler\n",
    "\n",
    "Fórmula de cálculo:\n",
    "\n",
    "$$X_{\\text{new}} = \\dfrac{X_i}{|X_{max}|}$$\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler)\n",
    "\n",
    "Padronização (Standard Scaler)\n",
    "* Os dados ficam centrados em 0, com dispersão igual a 1\n",
    "* Não obteremos uma distribuição normal (caso a distribuição original não for Normal; se a distribuição original for uma Normal teremos então uma distribuição Normal padrão)\n",
    "* Técnica sensível à outliers\n",
    "\n",
    "Fórmula de cálculo: \n",
    "\n",
    "$$Z = \\dfrac{X-\\mu}{\\sigma}$$\n",
    "\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n",
    "\n",
    "\n",
    "RobustScaler\n",
    "* Robusto à outlier, sendo similar ao MinMax, mas usa os quartis Q1 e Q3 para o scaling\n",
    "\n",
    "Fórmula de cálculo:\n",
    "\n",
    "$$\\dfrac{x_i-Q_1(X)}{Q_3(X)-Q_1(X)}$$\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler)\n",
    "\n",
    "PowerTransformer\n",
    "* Implementa as transformações de Yeo-Johnson (para valores positivos e negativos) e Box-Cox (para valores estritamente positivos).\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.PowerTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer)\n",
    "\n",
    "#### Variáveis qualitativas\n",
    "\n",
    "\n",
    "One-Hot-Encoder\n",
    "* Usado para criar dummies\n",
    "* Igual ao método do Pandas `pd.get_dummies()`, mas podemos usar o Sklearn por sua integração com as Pipelines\n",
    "* Se a variável tiver muitas categoricas, teremos muitas colunas criadas (alta dimensionalidade)\n",
    "\n",
    "<img src=\"https://i.imgur.com/TW5m0aJ.png\" height=700 width=700/>\n",
    "\n",
    "Implementação no Pandas: [pd.get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n",
    "Implementação no sklearn: []()\n",
    "\n",
    "\n",
    "Ordinal-Encoder\n",
    "* Usado para variáveis categóricas ordinais (nível de satisfação do usuário em uma escala de 1 a 5, em que 5 representa a satisfação máxima)\n",
    "\n",
    "Frequency-Encoder\n",
    "* Aplicação prática: coluna com muitos níveis/categorias ou se não houver grau ordinal\n",
    "* Cada nível da classe será substituído por sua frequência\n",
    "\n",
    "\n",
    "LabelEncoder\n",
    "* Encode para os labels da variável target, com 0 a n_classes-1\n",
    "* Deve ser usado para a variável target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Revisão\n",
    "\n",
    "Bussab e Morettin (2010) ressaltam que tanto a média, quanto o desvio padrão podem não ser medidas suficientes para se representar um conjunto de dados, pois: \n",
    "* ambos são afetados de forma demasiada por valores extremos;\n",
    "* não podemos ter uma noção clara da simetria ou assimetria da distribuição dos dados.\n",
    "\n",
    "*  1º Quartil: 25% das observações abaixo e 75% das observações acima\n",
    "*  2º  Quartil: 50% das observações abaixo e 50% das observações acima\n",
    "*  3º Quartil: 75% das observações abaixo e 25% das observações acima\n",
    "\n",
    "Então os quartis dividem o conjunto de dados em quatro partes iguais.\n",
    "\n",
    "\n",
    "Um boxtpot (gráfico de caixa) fornece uma poderosa visualização da distribuição dos dados e valores discrepantes (outliers), sendo formados pelo primeiro quartil, segundo quartil (mediana), terceiro quartil e limites superior e inferior. \n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Missing handling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas técnicas de imputação de missing:\n",
    "* SimpleImputer\n",
    "    * Imputa pela média, mediana, constante, moda (pode alterar drasticamente a distribuição da variável)\n",
    "    \n",
    "* KNNImputer\n",
    "    * Usa a técnica k-Nearest Neighbors para preencher os valores ausentes\n",
    "* Baseada no negócio\n",
    "    * Média/mediana de um grupo específico (faixa de renda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Métricas de avaliação de modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação de modelos de classificação**\n",
    "\n",
    "Vamos começar definindo os seguintes conceitos:\n",
    "\n",
    "* Classe postiiva (1): Cliente Mau\n",
    "* Classe negativa (0): Cliente Bom\n",
    "\n",
    "Uma definição de negócio para cliente mau poderia ser, um cliente com mais de 30 dias de atraso em uma janela de três meses.\n",
    "\n",
    "* VP: modelo acertou em dizer que era um cliente mau;\n",
    "* VN: modelo acertou em dizer que era um cliente bom;\n",
    "* FN: modelo errou em dizer que era um cliente mau;\n",
    "* FP: modelo errou em dizer que era um cliente bom.\n",
    "\n",
    "\n",
    "Acurácia\n",
    "\n",
    "\n",
    "A fórmula de cálculo da acurácia é:\n",
    "\n",
    "$$\\dfrac{VP+VN}{VP+VN+FP+FN}$$\n",
    "\n",
    "Dos verdadeiros positivos (Cliente Mau) e verdadeiros negativos (Cliente Bom) quantos o modelo acertou no total?\n",
    "\n",
    "Ou ainda, quanto o modelo acertou das previsões totais?\n",
    "\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "\n",
    "Outros aspectos da acurácia:\n",
    "* Ideal para problemas de classificação com classes balanceadas\n",
    "\n",
    "Precisão\n",
    "\n",
    "A fórmula de cálculo da precisão é:\n",
    "\n",
    "$$\\dfrac{VP}{VP+FP}$$\n",
    "\n",
    "De tudo que o modelo classificou como Cliente Mau, quantos realmente eram? (ocorrência do evento, classe 1)\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "\n",
    "Recall\n",
    "\n",
    "\n",
    "De todos os exemplos que são Cliente Mau, quantos foram classificados corretamente pelo modelo?\n",
    "\n",
    "A fórmula de cálculo do recall é:\n",
    "$$\\dfrac{VP}{VP+FN} $$\n",
    "\n",
    "\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    "\n",
    "\n",
    "F1-Score\n",
    "\n",
    "* Média harmônica do Recall e Precision.\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "\n",
    "Matriz de confusão\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    "\n",
    "\n",
    "* Indica a qualidade do modelo e agrega informações do que o modelo acertou e errou.\n",
    "\n",
    "<img src = 'https://diegonogare.net/wp-content/uploads/2020/04/matrizConfusao-600x381.png' width=500 height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vejamos uma implementação no Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hands On!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from boruta import BorutaPy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeção e Limpeza de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proporção da variável target\n",
    "df_train.Survived.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype de cada coluna\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.00</td>\n",
       "      <td>223.5000</td>\n",
       "      <td>446.0000</td>\n",
       "      <td>668.5</td>\n",
       "      <td>891.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std   min       25%       50%    75%  \\\n",
       "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
       "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
       "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
       "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
       "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
       "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
       "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
       "\n",
       "                  max  \n",
       "PassengerId  891.0000  \n",
       "Survived       1.0000  \n",
       "Pclass         3.0000  \n",
       "Age           80.0000  \n",
       "SibSp          8.0000  \n",
       "Parch          6.0000  \n",
       "Fare         512.3292  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sumário estatístico\n",
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         2\n",
       "Sex              2\n",
       "Pclass           3\n",
       "Embarked         3\n",
       "SibSp            7\n",
       "Parch            7\n",
       "Age             88\n",
       "Cabin          147\n",
       "Fare           248\n",
       "Ticket         681\n",
       "PassengerId    891\n",
       "Name           891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantidade de valores únicos em cada coluna\n",
    "df_train.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linhas duplicadas\n",
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coluna constante\n",
    "df_train.columns[df_train.nunique() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapeia as colunas com baixa variância (técnica de seleção de variáveis)\n",
    "threshold = 0.001\n",
    "scaler = MinMaxScaler()\n",
    "# colunas numéricas\n",
    "num_cols = df_train.select_dtypes(include = [int, float])\n",
    "scaled_num_cols = scaler.fit_transform(num_cols)\n",
    "scaled_num_df = pd.DataFrame(scaled_num_cols,\n",
    "                             columns = num_cols.columns\n",
    "                            )\n",
    "\n",
    "low_variance_columns = list()\n",
    "for column in scaled_num_df:\n",
    "    column_variance = scaled_num_df[column].var()\n",
    "    if column_variance < threshold:\n",
    "        low_variance_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para o threshold definido não identificamos nenhuma coluna com baixa variância\n",
    "low_variance_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Tarefa: transforme o código anterior em uma função.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0.00\n",
       "Survived        0.00\n",
       "Pclass          0.00\n",
       "Name            0.00\n",
       "Sex             0.00\n",
       "SibSp           0.00\n",
       "Parch           0.00\n",
       "Ticket          0.00\n",
       "Fare            0.00\n",
       "Embarked        0.22\n",
       "Age            19.87\n",
       "Cabin          77.10\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifica missing values\n",
    "(df_train.isna().sum()/df_train.shape[0] * 100).round(2).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos três colunas com missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder vamos separar os dados em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 999999\n",
    "train, test = train_test_split(\n",
    "                df_train,\n",
    "                test_size = 0.3,\n",
    "                random_state = SEED\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0.00\n",
       "Survived        0.00\n",
       "Pclass          0.00\n",
       "Name            0.00\n",
       "Sex             0.00\n",
       "SibSp           0.00\n",
       "Parch           0.00\n",
       "Ticket          0.00\n",
       "Fare            0.00\n",
       "Embarked        0.00\n",
       "Age            20.22\n",
       "Cabin          78.17\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.isna().sum()/train.shape[0] * 100).round(2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nan(df):\n",
    "    # imputa os valores ausentes pela moda\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode().squeeze())\n",
    "    # Se possui Cabine 1, 0 caso contrário\n",
    "    df['Cabin'] = np.where(df.Cabin.isna(), 0, 1)\n",
    "    # imputa os valores ausentes de idade pela categoria de Sexo e Sobrevivência\n",
    "    df['category'] = df['Sex'] + '-' + df['Pclass'].astype(str)\n",
    "    categories = dict()\n",
    "    for i in df.category.unique():\n",
    "        filtered_data = df.loc[df.category == i]\n",
    "        median = filtered_data.Age.median()\n",
    "        categories[i] = median\n",
    "\n",
    "    nan_values = df.Age.isna()\n",
    "    df.loc[nan_values, 'Age'] = df.loc[nan_values, 'category'].map(categories)\n",
    "    df = df.drop(columns = 'category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clean_nan(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop de colunas que não serão utilizadas\n",
    "train.drop(columns = ['PassengerId', 'Name', 'Ticket'], inplace = True)\n",
    "test.drop(columns = ['PassengerId', 'Name', 'Ticket'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_vars(df):\n",
    "    df['Age_groups'] = pd.cut(df.Age, 5, labels = False)\n",
    "    df['Size'] = df.eval('SibSp+Parch')\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = new_vars(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clean_nan(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = new_vars(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns = ['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass          int64\n",
       "Age           float64\n",
       "SibSp           int64\n",
       "Parch           int64\n",
       "Fare          float64\n",
       "Cabin           int32\n",
       "Age_groups      int64\n",
       "Size            int64\n",
       "Sex_male        uint8\n",
       "Embarked_Q      uint8\n",
       "Embarked_S      uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state = SEED)\n",
    "reg_log = LogisticRegression()\n",
    "# validação cruzada regressão logística\n",
    "cross_val_reg_log = cross_validate(estimator = reg_log,\n",
    "                                   X = X_train,\n",
    "                                   y = y_train,\n",
    "                                   scoring = 'roc_auc',\n",
    "                                   cv = cv,\n",
    "                                   return_train_score = True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.86985809896708, 0.8579079842463301)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_reg_log['train_score'].mean(), cross_val_reg_log['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "clf_reg_log = RandomizedSearchCV(\n",
    "    estimator = reg_log,\n",
    "    param_distributions = param_grid,\n",
    "    scoring = 'roc_auc',\n",
    "    random_state = SEED,\n",
    "    n_iter = 100,\n",
    "    n_jobs = -1,\n",
    "    verbose = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1, 0.5, 1],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                    'none']},\n",
       "                   random_state=999999, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_reg_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'class_weight': None, 'C': 0.5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melhores hiperparâmetros\n",
    "clf_reg_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = clf_reg_log.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = clf_reg_log.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métrica no treino e test\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8680596047942988, 0.8223608850304455)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train , roc_auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Age_groups</th>\n",
       "      <th>Size</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.272388</td>\n",
       "      <td>29.274254</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.369403</td>\n",
       "      <td>33.043485</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>1.570896</td>\n",
       "      <td>0.847015</td>\n",
       "      <td>0.660448</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.727612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.859221</td>\n",
       "      <td>13.196090</td>\n",
       "      <td>0.888684</td>\n",
       "      <td>0.740556</td>\n",
       "      <td>57.040359</td>\n",
       "      <td>0.435960</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>1.377627</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>0.275015</td>\n",
       "      <td>0.446021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.772900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age       SibSp       Parch        Fare       Cabin  \\\n",
       "count  268.000000  268.000000  268.000000  268.000000  268.000000  268.000000   \n",
       "mean     2.272388   29.274254    0.477612    0.369403   33.043485    0.253731   \n",
       "std      0.859221   13.196090    0.888684    0.740556   57.040359    0.435960   \n",
       "min      1.000000    0.420000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   21.000000    0.000000    0.000000    7.925000    0.000000   \n",
       "50%      3.000000   27.000000    0.000000    0.000000   14.772900    0.000000   \n",
       "75%      3.000000   36.000000    1.000000    0.000000   33.125000    1.000000   \n",
       "max      3.000000   71.000000    5.000000    5.000000  512.329200    1.000000   \n",
       "\n",
       "       Age_groups        Size    Sex_male  Embarked_Q  Embarked_S  \n",
       "count  268.000000  268.000000  268.000000  268.000000  268.000000  \n",
       "mean     1.570896    0.847015    0.660448    0.082090    0.727612  \n",
       "std      0.931458    1.377627    0.474443    0.275015    0.446021  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      1.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    1.000000    0.000000    1.000000  \n",
       "75%      2.000000    1.000000    1.000000    0.000000    1.000000  \n",
       "max      4.000000    7.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva modelo\n",
    "pickle.dump(clf_reg_log, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Homework**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como parte dos estudos extra-classe analise as possibilidades de pré-processamento que foram aplicadas no exemplo a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from pandas_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m diabetes \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diabetes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdiabetes\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diabetes' is not defined"
     ]
    }
   ],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preg     0\n",
       "plas     0\n",
       "pres     0\n",
       "skin     0\n",
       "insu     0\n",
       "mass     0\n",
       "pedi     0\n",
       "age      0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diabetes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdiabetes\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m diabetes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diabetes' is not defined"
     ]
    }
   ],
   "source": [
    "X = diabetes.drop(columns = 'class')\n",
    "y = diabetes['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.3,\n",
    "    random_state = SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.map({\"tested_negative\":0,\"tested_positive\":1})\n",
    "y_test = y_test.map({\"tested_negative\":0,\"tested_positive\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gráfico de dispersão\n",
    "n_linhas = 4\n",
    "colunas = 2\n",
    "posicao = 1\n",
    "# Tamanho das Figuras\n",
    "plt.subplots(figsize=(15,10))\n",
    "# Título\n",
    "plt.suptitle('Análise das variáveis independentes - Gráfico de Dispersão', fontsize=22, color='#404040', fontweight=600, y = 1.3)\n",
    "# Plotar as 23 colunas no X\n",
    "for coluna in X.columns:\n",
    "    plt.subplot(n_linhas,colunas,posicao)\n",
    "    plt.scatter(wage_data[coluna], wage_data['wage'])\n",
    "    plt.xlabel(coluna)\n",
    "    plt.ylabel('Wage')\n",
    "    posicao += 1\n",
    "# Ajuste de Grid\n",
    "plt.subplots_adjust( top=1.2, hspace=1.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplica o RobustScaler nas features\n",
    "scaler = RobustScaler()\n",
    "train = scaler.fit_transform(X_train)\n",
    "test = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(train, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(test, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV com KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'metric': ['minkowski', 'chebyshev'],\n",
       "                         'n_neighbors': array([ 3,  5,  7,  9, 11, 13]),\n",
       "                         'p': array([1, 2, 3, 4]),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier()\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    random_state=SEED, \n",
    "    shuffle=True\n",
    ")\n",
    "# espaço de pesquisa de hiperparâmetros\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': np.arange(3, 15, 2),\n",
    "    'p': np.arange(1, 5),\n",
    "    'metric': ['minkowski', 'chebyshev'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# grid search\n",
    "grid_knn = GridSearchCV(\n",
    "    estimator=clf_knn,\n",
    "    param_grid=param_grid_knn,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# treino\n",
    "grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = grid_knn.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = grid_knn.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = grid_knn.predict(X_train)\n",
    "y_pred_test = grid_knn.predict(X_test)\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.7547094508301404\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_train, roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       144\n",
      "           1       0.76      0.43      0.54        87\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.74      0.67      0.68       231\n",
      "weighted avg       0.74      0.73      0.71       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=10, shuffle=True),\n",
       "                   estimator=LogisticRegression(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000027494832BE0>,\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'penalty': ['l1', 'l2', 'elastic_net',\n",
       "                                                    'none']},\n",
       "                   random_state=10, return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "clf_reg_log = LogisticRegression()\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5, \n",
    "    random_state=SEED, \n",
    "    shuffle=True\n",
    ")\n",
    "# espaço de pesquisa de hiperparâmetros\n",
    "param_distributions_reg_log = {\n",
    "    'C': loguniform(1e-5, 100),\n",
    "    'penalty': ['l1', 'l2', 'elastic_net', 'none'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# random search\n",
    "random_reg_log = RandomizedSearchCV(\n",
    "    estimator=clf_reg_log,\n",
    "    param_distributions=param_distributions_reg_log,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    return_train_score=True,\n",
    "    n_iter=100\n",
    ")\n",
    "\n",
    "# treino\n",
    "random_reg_log.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = random_reg_log.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = random_reg_log.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = random_reg_log.predict(X_train)\n",
    "y_pred_test = random_reg_log.predict(X_test)\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8453659445030728 0.8164910600255428\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_train, roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       144\n",
      "           1       0.77      0.49      0.60        87\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.76      0.70      0.71       231\n",
      "weighted avg       0.76      0.75      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# relatório das métricas de avaliação\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_reg_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'boosting_type': ['gbdt'],\n",
       "                                        'colsample_bytree': [0.5, 0.7],\n",
       "                                        'learning_rate': [0.05],\n",
       "                                        'max_depth': [5, 6, 7, 8],\n",
       "                                        'metric': ['auc'],\n",
       "                                        'min_data_in_leaf': [10],\n",
       "                                        'min_split_gain': [0.01],\n",
       "                                        'num_leaves': [90, 200],\n",
       "                                        'objective': ['binary'],\n",
       "                                        'random_state': [501],\n",
       "                                        'subsample': [0.5, 0.7]},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves': [90,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [5,6,7,8],\n",
    "    'random_state' : [501], \n",
    "    'colsample_bytree' : [0.5,0.7],\n",
    "    'subsample' : [0.5,0.7],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "    'metric':['auc']\n",
    "    }\n",
    "\n",
    "\n",
    "#modelling\n",
    "clf = LGBMClassifier()\n",
    "grid = RandomizedSearchCV(clf,gridParams,verbose=1,cv=10,n_jobs = -1,n_iter=10)\n",
    "grid.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = grid.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = grid.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = grid.predict(X_train)\n",
    "y_pred_test = grid.predict(X_test)\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999068843503632 0.8126596424010217\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_train, roc_auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels. This is present only if ``refit`` is specified and\n",
      " |      the underlying estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `n_features_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `feature_names_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Result of the decision function for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Instance of fitted estimator.\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Result of the `inverse_transform` function for `Xt` based on the\n",
      " |          estimator with the best found parameters.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted labels or values for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class log-probabilities for `X` based on the estimator\n",
      " |          with the best found parameters. The order of the classes\n",
      " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class probabilities for `X` based on the estimator with\n",
      " |          the best found parameters. The order of the classes corresponds\n",
      " |          to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Return the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          The score defined by ``scoring`` if provided, and the\n",
      " |          ``best_estimator_.score`` method otherwise.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |          The ``best_estimator_.score_samples`` method.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          `X` transformed in the new space based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |      Class labels.\n",
      " |      \n",
      " |      Only available when `refit=True` and the estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |      \n",
      " |      Only available when `refit=True`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337],\n",
    "              'C': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "              'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "              'class_weight': ['balanced', None]}\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(n_splits = 5, shuffle=True, random_state = 10), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[20:32:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0ac76685cf763591d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"C\", \"class_weight\", \"penalty\", \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_typ...\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'colsample_bytree': [0.7], 'learning_rate': [0.05],\n",
       "                         'max_depth': [6], 'min_child_weight': [11],\n",
       "                         'missing': [-999], 'n_estimators': [5], 'nthread': [4],\n",
       "                         'objective': ['binary:logistic'],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'seed': [1337], 'silent': [1], 'subsample': [0.8]},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = clf.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métrica no treino e test\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8745809795766343, 0.7957774584929758)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train , roc_auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81       191\n",
      "           1       0.37      0.80      0.50        40\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.66      0.76      0.66       231\n",
      "weighted avg       0.84      0.73      0.76       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checando as distribuições\n",
    "sns.histplot(X_train['age'])\n",
    "plt.show()\n",
    "sns.histplot(X_train['mass'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora usaremos o scikit-learn para aplicar o MinMaxScaler, RobustScaler e StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora precisamos usar os métodos `fit()` e `transform()`. O `fit()` irá realizar a extração do que precisa para realizar a transformação, no caso do MinMax, equivale à extrair os valores mínimo e máximo. Em seguida, usamos o método `transform()` para realizar a transformação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos aplicar o MinMax na features `mass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    537.000000\n",
       "mean      31.963873\n",
       "std        7.819653\n",
       "min        0.000000\n",
       "25%       27.500000\n",
       "50%       32.000000\n",
       "75%       36.500000\n",
       "max       67.100000\n",
       "Name: mass, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mass.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler.fit(X_train[['mass']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49925484],\n",
       "       [0.43070045],\n",
       "       [0.40983607],\n",
       "       [0.5752608 ],\n",
       "       [0.30402385],\n",
       "       [0.45454545],\n",
       "       [0.42324888],\n",
       "       [0.35320417],\n",
       "       [0.52011923],\n",
       "       [0.29210134],\n",
       "       [0.4485842 ],\n",
       "       [0.3681073 ],\n",
       "       [0.59165425],\n",
       "       [0.31445604],\n",
       "       [0.4709389 ],\n",
       "       [0.52160954],\n",
       "       [0.4366617 ],\n",
       "       [0.47690015],\n",
       "       [0.50074516],\n",
       "       [0.41132638],\n",
       "       [0.41728763],\n",
       "       [0.56184799],\n",
       "       [0.48733234],\n",
       "       [0.46050671],\n",
       "       [0.32637854],\n",
       "       [0.37406855],\n",
       "       [0.37257824],\n",
       "       [0.48137109],\n",
       "       [0.49627422],\n",
       "       [0.31594635],\n",
       "       [0.52757079],\n",
       "       [0.50968703],\n",
       "       [0.54843517],\n",
       "       [0.64679583],\n",
       "       [0.45901639],\n",
       "       [0.58271237],\n",
       "       [0.42771982],\n",
       "       [0.46497765],\n",
       "       [0.56780924],\n",
       "       [0.47690015],\n",
       "       [0.47690015],\n",
       "       [0.60804769],\n",
       "       [0.54694486],\n",
       "       [0.49627422],\n",
       "       [0.59463487],\n",
       "       [0.51862891],\n",
       "       [0.8852459 ],\n",
       "       [0.38152012],\n",
       "       [0.40834575],\n",
       "       [0.32488823],\n",
       "       [0.4023845 ],\n",
       "       [0.4023845 ],\n",
       "       [0.48882265],\n",
       "       [0.48435171],\n",
       "       [0.39642325],\n",
       "       [0.56184799],\n",
       "       [0.42771982],\n",
       "       [0.57078987],\n",
       "       [0.4828614 ],\n",
       "       [0.68852459],\n",
       "       [0.53502235],\n",
       "       [0.55737705],\n",
       "       [0.38897168],\n",
       "       [0.52608048],\n",
       "       [0.66318927],\n",
       "       [0.45901639],\n",
       "       [0.51117735],\n",
       "       [0.41728763],\n",
       "       [0.55439642],\n",
       "       [0.67362146],\n",
       "       [0.43964232],\n",
       "       [0.53353204],\n",
       "       [0.49031297],\n",
       "       [0.36065574],\n",
       "       [0.58420268],\n",
       "       [0.53502235],\n",
       "       [0.49627422],\n",
       "       [0.58867362],\n",
       "       [0.5052161 ],\n",
       "       [0.4828614 ],\n",
       "       [0.57228018],\n",
       "       [0.42026826],\n",
       "       [0.71385991],\n",
       "       [0.49329359],\n",
       "       [0.55290611],\n",
       "       [0.63040238],\n",
       "       [0.38897168],\n",
       "       [0.45901639],\n",
       "       [0.28912072],\n",
       "       [0.45454545],\n",
       "       [0.44560358],\n",
       "       [0.51117735],\n",
       "       [0.29061103],\n",
       "       [0.44560358],\n",
       "       [0.49329359],\n",
       "       [0.44709389],\n",
       "       [0.37257824],\n",
       "       [0.42771982],\n",
       "       [0.62295082],\n",
       "       [0.35320417],\n",
       "       [0.48435171],\n",
       "       [0.46497765],\n",
       "       [0.51415797],\n",
       "       [0.36661699],\n",
       "       [0.48733234],\n",
       "       [0.38152012],\n",
       "       [0.49031297],\n",
       "       [0.48882265],\n",
       "       [0.52160954],\n",
       "       [0.32637854],\n",
       "       [0.4485842 ],\n",
       "       [0.61847988],\n",
       "       [0.31296572],\n",
       "       [0.41877794],\n",
       "       [0.47690015],\n",
       "       [0.36214605],\n",
       "       [0.54843517],\n",
       "       [0.4709389 ],\n",
       "       [0.3442623 ],\n",
       "       [0.4709389 ],\n",
       "       [0.54992548],\n",
       "       [0.34575261],\n",
       "       [0.41728763],\n",
       "       [0.41281669],\n",
       "       [0.56631893],\n",
       "       [0.85394933],\n",
       "       [0.54098361],\n",
       "       [0.38599106],\n",
       "       [0.33084948],\n",
       "       [0.41579732],\n",
       "       [0.37704918],\n",
       "       [0.45454545],\n",
       "       [0.56035768],\n",
       "       [0.        ],\n",
       "       [0.53353204],\n",
       "       [0.67064083],\n",
       "       [0.38002981],\n",
       "       [0.35022355],\n",
       "       [0.51117735],\n",
       "       [0.43964232],\n",
       "       [0.64828614],\n",
       "       [0.64679583],\n",
       "       [0.41728763],\n",
       "       [0.609538  ],\n",
       "       [0.41132638],\n",
       "       [0.4828614 ],\n",
       "       [0.50670641],\n",
       "       [0.67511177],\n",
       "       [0.38450075],\n",
       "       [0.50968703],\n",
       "       [0.53204173],\n",
       "       [0.52309985],\n",
       "       [0.44262295],\n",
       "       [0.55886736],\n",
       "       [0.58718331],\n",
       "       [0.62742176],\n",
       "       [0.58122206],\n",
       "       [0.41132638],\n",
       "       [0.57377049],\n",
       "       [0.74068554],\n",
       "       [0.45305514],\n",
       "       [0.68852459],\n",
       "       [0.46348733],\n",
       "       [0.29210134],\n",
       "       [0.        ],\n",
       "       [0.4709389 ],\n",
       "       [0.27123696],\n",
       "       [0.52309985],\n",
       "       [0.3681073 ],\n",
       "       [0.        ],\n",
       "       [0.40983607],\n",
       "       [0.45007452],\n",
       "       [0.50372578],\n",
       "       [0.39344262],\n",
       "       [0.4247392 ],\n",
       "       [0.50372578],\n",
       "       [0.38748137],\n",
       "       [0.43964232],\n",
       "       [0.66318927],\n",
       "       [0.5171386 ],\n",
       "       [0.44560358],\n",
       "       [0.39642325],\n",
       "       [0.609538  ],\n",
       "       [0.49031297],\n",
       "       [0.48435171],\n",
       "       [0.3561848 ],\n",
       "       [0.4485842 ],\n",
       "       [0.32488823],\n",
       "       [0.53204173],\n",
       "       [0.40536513],\n",
       "       [0.44262295],\n",
       "       [0.53800298],\n",
       "       [0.50223547],\n",
       "       [0.36065574],\n",
       "       [0.4709389 ],\n",
       "       [0.44262295],\n",
       "       [0.55439642],\n",
       "       [0.59314456],\n",
       "       [0.40685544],\n",
       "       [0.50968703],\n",
       "       [0.38897168],\n",
       "       [0.6557377 ],\n",
       "       [0.67958271],\n",
       "       [0.50968703],\n",
       "       [0.4366617 ],\n",
       "       [0.3681073 ],\n",
       "       [0.64530551],\n",
       "       [0.51564829],\n",
       "       [0.5290611 ],\n",
       "       [0.45454545],\n",
       "       [0.42324888],\n",
       "       [0.43219076],\n",
       "       [0.48882265],\n",
       "       [0.50670641],\n",
       "       [0.45901639],\n",
       "       [0.56929955],\n",
       "       [0.46050671],\n",
       "       [0.45454545],\n",
       "       [0.48882265],\n",
       "       [0.45305514],\n",
       "       [1.        ],\n",
       "       [0.54843517],\n",
       "       [0.50670641],\n",
       "       [0.74515648],\n",
       "       [0.38599106],\n",
       "       [0.56482861],\n",
       "       [0.56929955],\n",
       "       [0.44411326],\n",
       "       [0.35171386],\n",
       "       [0.42324888],\n",
       "       [0.73919523],\n",
       "       [0.34873323],\n",
       "       [0.57377049],\n",
       "       [0.45901639],\n",
       "       [0.61549925],\n",
       "       [0.59463487],\n",
       "       [0.55588674],\n",
       "       [0.55439642],\n",
       "       [0.44113264],\n",
       "       [0.50372578],\n",
       "       [0.5633383 ],\n",
       "       [0.52757079],\n",
       "       [0.38152012],\n",
       "       [0.63934426],\n",
       "       [0.48435171],\n",
       "       [0.46497765],\n",
       "       [0.3099851 ],\n",
       "       [0.60357675],\n",
       "       [0.65871833],\n",
       "       [0.34724292],\n",
       "       [0.4947839 ],\n",
       "       [0.46497765],\n",
       "       [0.36959762],\n",
       "       [0.57377049],\n",
       "       [0.        ],\n",
       "       [0.35469449],\n",
       "       [0.        ],\n",
       "       [0.68107303],\n",
       "       [0.37555887],\n",
       "       [0.60357675],\n",
       "       [0.32488823],\n",
       "       [0.46050671],\n",
       "       [0.3338301 ],\n",
       "       [0.50819672],\n",
       "       [0.52011923],\n",
       "       [0.54396423],\n",
       "       [0.51862891],\n",
       "       [0.66467958],\n",
       "       [0.44113264],\n",
       "       [0.53651267],\n",
       "       [0.35916542],\n",
       "       [0.50819672],\n",
       "       [0.54545455],\n",
       "       [0.37853949],\n",
       "       [0.53502235],\n",
       "       [0.51266766],\n",
       "       [0.47690015],\n",
       "       [0.49627422],\n",
       "       [0.34128167],\n",
       "       [0.53204173],\n",
       "       [0.585693  ],\n",
       "       [0.54396423],\n",
       "       [0.47690015],\n",
       "       [0.56184799],\n",
       "       [0.44560358],\n",
       "       [0.37257824],\n",
       "       [0.58867362],\n",
       "       [0.40983607],\n",
       "       [0.47690015],\n",
       "       [0.3099851 ],\n",
       "       [0.414307  ],\n",
       "       [0.41728763],\n",
       "       [0.36065574],\n",
       "       [0.4947839 ],\n",
       "       [0.49031297],\n",
       "       [0.45752608],\n",
       "       [0.51564829],\n",
       "       [0.390462  ],\n",
       "       [0.59612519],\n",
       "       [0.46497765],\n",
       "       [0.61549925],\n",
       "       [0.54545455],\n",
       "       [0.53651267],\n",
       "       [0.4709389 ],\n",
       "       [0.77943368],\n",
       "       [0.38152012],\n",
       "       [0.64977645],\n",
       "       [0.        ],\n",
       "       [0.4947839 ],\n",
       "       [0.56184799],\n",
       "       [0.5290611 ],\n",
       "       [0.57377049],\n",
       "       [0.51117735],\n",
       "       [0.2876304 ],\n",
       "       [0.44709389],\n",
       "       [0.42771982],\n",
       "       [0.44411326],\n",
       "       [0.58420268],\n",
       "       [0.29955291],\n",
       "       [0.51266766],\n",
       "       [0.49627422],\n",
       "       [0.46050671],\n",
       "       [0.42324888],\n",
       "       [0.53502235],\n",
       "       [0.45901639],\n",
       "       [0.48733234],\n",
       "       [0.414307  ],\n",
       "       [0.49031297],\n",
       "       [0.43070045],\n",
       "       [0.40983607],\n",
       "       [0.51117735],\n",
       "       [0.42175857],\n",
       "       [0.33830104],\n",
       "       [0.47690015],\n",
       "       [0.50223547],\n",
       "       [0.43070045],\n",
       "       [0.67958271],\n",
       "       [0.53204173],\n",
       "       [0.5171386 ],\n",
       "       [0.50074516],\n",
       "       [0.        ],\n",
       "       [0.34277198],\n",
       "       [0.41132638],\n",
       "       [0.52160954],\n",
       "       [0.50074516],\n",
       "       [0.61400894],\n",
       "       [0.35022355],\n",
       "       [0.33233979],\n",
       "       [0.56780924],\n",
       "       [0.5290611 ],\n",
       "       [0.36512668],\n",
       "       [0.64530551],\n",
       "       [0.40387481],\n",
       "       [0.52757079],\n",
       "       [0.4485842 ],\n",
       "       [0.54545455],\n",
       "       [0.56929955],\n",
       "       [0.49627422],\n",
       "       [0.44262295],\n",
       "       [0.47540984],\n",
       "       [0.37853949],\n",
       "       [0.4709389 ],\n",
       "       [0.55737705],\n",
       "       [0.390462  ],\n",
       "       [0.54396423],\n",
       "       [0.42921013],\n",
       "       [0.38599106],\n",
       "       [0.42771982],\n",
       "       [0.3442623 ],\n",
       "       [0.37555887],\n",
       "       [0.5633383 ],\n",
       "       [0.43219076],\n",
       "       [0.34575261],\n",
       "       [0.4947839 ],\n",
       "       [0.36959762],\n",
       "       [0.55737705],\n",
       "       [0.4828614 ],\n",
       "       [0.39642325],\n",
       "       [0.35022355],\n",
       "       [0.47540984],\n",
       "       [0.58718331],\n",
       "       [0.62891207],\n",
       "       [0.45156483],\n",
       "       [0.34724292],\n",
       "       [0.63487332],\n",
       "       [0.32488823],\n",
       "       [0.55886736],\n",
       "       [0.33532042],\n",
       "       [0.52011923],\n",
       "       [0.50074516],\n",
       "       [0.6318927 ],\n",
       "       [0.6780924 ],\n",
       "       [0.57675112],\n",
       "       [0.42771982],\n",
       "       [0.50819672],\n",
       "       [0.39344262],\n",
       "       [0.54098361],\n",
       "       [0.29061103],\n",
       "       [0.38748137],\n",
       "       [0.61549925],\n",
       "       [0.4828614 ],\n",
       "       [0.38599106],\n",
       "       [0.52011923],\n",
       "       [0.58271237],\n",
       "       [0.60506706],\n",
       "       [0.54396423],\n",
       "       [0.31445604],\n",
       "       [0.48137109],\n",
       "       [0.4366617 ],\n",
       "       [0.45305514],\n",
       "       [0.5052161 ],\n",
       "       [0.37704918],\n",
       "       [0.63636364],\n",
       "       [0.61847988],\n",
       "       [0.49627422],\n",
       "       [0.60506706],\n",
       "       [0.45901639],\n",
       "       [0.5976155 ],\n",
       "       [0.59463487],\n",
       "       [0.51415797],\n",
       "       [0.48882265],\n",
       "       [0.36065574],\n",
       "       [0.5290611 ],\n",
       "       [0.57675112],\n",
       "       [0.37406855],\n",
       "       [0.37406855],\n",
       "       [0.28464978],\n",
       "       [0.59910581],\n",
       "       [0.44113264],\n",
       "       [0.46497765],\n",
       "       [0.40536513],\n",
       "       [0.44262295],\n",
       "       [0.41132638],\n",
       "       [0.50223547],\n",
       "       [0.40387481],\n",
       "       [0.37257824],\n",
       "       [0.36065574],\n",
       "       [0.27123696],\n",
       "       [0.4947839 ],\n",
       "       [0.50968703],\n",
       "       [0.38599106],\n",
       "       [0.4709389 ],\n",
       "       [0.49031297],\n",
       "       [0.4366617 ],\n",
       "       [0.414307  ],\n",
       "       [0.43964232],\n",
       "       [0.54992548],\n",
       "       [0.37853949],\n",
       "       [0.44560358],\n",
       "       [0.58718331],\n",
       "       [0.53502235],\n",
       "       [0.64530551],\n",
       "       [0.37257824],\n",
       "       [0.5290611 ],\n",
       "       [0.45901639],\n",
       "       [0.50968703],\n",
       "       [0.56035768],\n",
       "       [0.414307  ],\n",
       "       [0.46497765],\n",
       "       [0.31445604],\n",
       "       [0.57675112],\n",
       "       [0.32488823],\n",
       "       [0.46497765],\n",
       "       [0.54992548],\n",
       "       [0.41281669],\n",
       "       [0.52011923],\n",
       "       [0.48882265],\n",
       "       [0.56631893],\n",
       "       [0.64232489],\n",
       "       [0.58718331],\n",
       "       [0.40834575],\n",
       "       [0.57824143],\n",
       "       [0.44709389],\n",
       "       [0.50372578],\n",
       "       [0.33084948],\n",
       "       [0.57973174],\n",
       "       [0.5290611 ],\n",
       "       [0.44709389],\n",
       "       [0.42622951],\n",
       "       [0.40834575],\n",
       "       [0.35767511],\n",
       "       [0.58271237],\n",
       "       [0.44709389],\n",
       "       [0.32935917],\n",
       "       [0.53353204],\n",
       "       [0.47690015],\n",
       "       [0.50670641],\n",
       "       [0.6900149 ],\n",
       "       [0.59612519],\n",
       "       [0.43070045],\n",
       "       [0.40834575],\n",
       "       [0.35469449],\n",
       "       [0.44411326],\n",
       "       [0.45305514],\n",
       "       [0.58867362],\n",
       "       [0.4709389 ],\n",
       "       [0.50819672],\n",
       "       [0.39493294],\n",
       "       [0.50074516],\n",
       "       [0.47690015],\n",
       "       [0.39940387],\n",
       "       [0.37853949],\n",
       "       [0.6318927 ],\n",
       "       [0.4485842 ],\n",
       "       [0.29210134],\n",
       "       [0.56184799],\n",
       "       [0.73472429],\n",
       "       [0.63040238],\n",
       "       [0.68703428],\n",
       "       [0.46199702],\n",
       "       [0.51415797],\n",
       "       [0.4485842 ],\n",
       "       [0.50074516],\n",
       "       [0.57377049],\n",
       "       [0.54843517],\n",
       "       [0.5171386 ],\n",
       "       [0.41281669],\n",
       "       [0.27421759],\n",
       "       [0.49627422],\n",
       "       [0.45901639],\n",
       "       [0.        ],\n",
       "       [0.67511177],\n",
       "       [0.58122206],\n",
       "       [0.50670641],\n",
       "       [0.54843517],\n",
       "       [0.4485842 ],\n",
       "       [0.52309985],\n",
       "       [0.45454545],\n",
       "       [0.38748137],\n",
       "       [0.43219076],\n",
       "       [0.36661699],\n",
       "       [0.39940387],\n",
       "       [0.48882265],\n",
       "       [0.40983607],\n",
       "       [0.39195231],\n",
       "       [0.81967213],\n",
       "       [0.50074516]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler.transform(X_train[['mass']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar também o método `fit_transform()` para realizar a extração dos parâmetros e aplicar a transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_new = min_max_scaler.fit_transform(X_train[['mass']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novos valores máximo e mínimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_new.min(), mass_new.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_new = pd.DataFrame(mass_new, columns = ['mass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>537.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.476362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.116537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.409836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.476900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.543964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mass\n",
       "count  537.000000\n",
       "mean     0.476362\n",
       "std      0.116537\n",
       "min      0.000000\n",
       "25%      0.409836\n",
       "50%      0.476900\n",
       "75%      0.543964\n",
       "max      1.000000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos aplicar o StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplica a transformação em todo o conjunto de dados\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standard = standard_scaler.fit_transform(X_train)\n",
    "X_train_standard = pd.DataFrame(X_train_standard, columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.370000e+02</td>\n",
       "      <td>5.370000e+02</td>\n",
       "      <td>5.370000e+02</td>\n",
       "      <td>5.370000e+02</td>\n",
       "      <td>5.370000e+02</td>\n",
       "      <td>5.370000e+02</td>\n",
       "      <td>5.370000e+02</td>\n",
       "      <td>5.370000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.736662e-17</td>\n",
       "      <td>-6.202363e-19</td>\n",
       "      <td>-2.860840e-16</td>\n",
       "      <td>-8.838368e-17</td>\n",
       "      <td>2.305212e-16</td>\n",
       "      <td>3.441278e-16</td>\n",
       "      <td>5.954269e-17</td>\n",
       "      <td>-2.516092e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000932e+00</td>\n",
       "      <td>1.000932e+00</td>\n",
       "      <td>1.000932e+00</td>\n",
       "      <td>1.000932e+00</td>\n",
       "      <td>1.000932e+00</td>\n",
       "      <td>1.000932e+00</td>\n",
       "      <td>1.000932e+00</td>\n",
       "      <td>1.000932e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.137138e+00</td>\n",
       "      <td>-3.686267e+00</td>\n",
       "      <td>-3.626219e+00</td>\n",
       "      <td>-1.346719e+00</td>\n",
       "      <td>-6.928023e-01</td>\n",
       "      <td>-4.091444e+00</td>\n",
       "      <td>-1.154989e+00</td>\n",
       "      <td>-1.030465e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.375094e-01</td>\n",
       "      <td>-6.788854e-01</td>\n",
       "      <td>-2.825322e-01</td>\n",
       "      <td>-1.346719e+00</td>\n",
       "      <td>-6.928023e-01</td>\n",
       "      <td>-5.713854e-01</td>\n",
       "      <td>-6.748518e-01</td>\n",
       "      <td>-7.762806e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.382522e-01</td>\n",
       "      <td>-1.320888e-01</td>\n",
       "      <td>1.354286e-01</td>\n",
       "      <td>1.849184e-01</td>\n",
       "      <td>-3.362530e-01</td>\n",
       "      <td>4.624286e-03</td>\n",
       "      <td>-2.967439e-01</td>\n",
       "      <td>-3.526397e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.606336e-01</td>\n",
       "      <td>6.577285e-01</td>\n",
       "      <td>5.533894e-01</td>\n",
       "      <td>6.954643e-01</td>\n",
       "      <td>3.606386e-01</td>\n",
       "      <td>5.806339e-01</td>\n",
       "      <td>4.024556e-01</td>\n",
       "      <td>6.640986e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.956548e+00</td>\n",
       "      <td>2.358874e+00</td>\n",
       "      <td>2.747684e+00</td>\n",
       "      <td>4.971286e+00</td>\n",
       "      <td>6.162667e+00</td>\n",
       "      <td>4.497500e+00</td>\n",
       "      <td>5.873017e+00</td>\n",
       "      <td>4.053226e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               preg          plas          pres          skin          insu  \\\n",
       "count  5.370000e+02  5.370000e+02  5.370000e+02  5.370000e+02  5.370000e+02   \n",
       "mean  -1.736662e-17 -6.202363e-19 -2.860840e-16 -8.838368e-17  2.305212e-16   \n",
       "std    1.000932e+00  1.000932e+00  1.000932e+00  1.000932e+00  1.000932e+00   \n",
       "min   -1.137138e+00 -3.686267e+00 -3.626219e+00 -1.346719e+00 -6.928023e-01   \n",
       "25%   -8.375094e-01 -6.788854e-01 -2.825322e-01 -1.346719e+00 -6.928023e-01   \n",
       "50%   -2.382522e-01 -1.320888e-01  1.354286e-01  1.849184e-01 -3.362530e-01   \n",
       "75%    6.606336e-01  6.577285e-01  5.533894e-01  6.954643e-01  3.606386e-01   \n",
       "max    3.956548e+00  2.358874e+00  2.747684e+00  4.971286e+00  6.162667e+00   \n",
       "\n",
       "               mass          pedi           age  \n",
       "count  5.370000e+02  5.370000e+02  5.370000e+02  \n",
       "mean   3.441278e-16  5.954269e-17 -2.516092e-16  \n",
       "std    1.000932e+00  1.000932e+00  1.000932e+00  \n",
       "min   -4.091444e+00 -1.154989e+00 -1.030465e+00  \n",
       "25%   -5.713854e-01 -6.748518e-01 -7.762806e-01  \n",
       "50%    4.624286e-03 -2.967439e-01 -3.526397e-01  \n",
       "75%    5.806339e-01  4.024556e-01  6.640986e-01  \n",
       "max    4.497500e+00  5.873017e+00  4.053226e+00  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_standard.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.537881</td>\n",
       "      <td>-0.982661</td>\n",
       "      <td>1.075840</td>\n",
       "      <td>0.567828</td>\n",
       "      <td>-0.692802</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>-0.512806</td>\n",
       "      <td>0.748827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061376</td>\n",
       "      <td>0.748861</td>\n",
       "      <td>0.814615</td>\n",
       "      <td>0.376373</td>\n",
       "      <td>0.117537</td>\n",
       "      <td>-0.392182</td>\n",
       "      <td>-0.821894</td>\n",
       "      <td>-0.522096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.859148</td>\n",
       "      <td>-0.314354</td>\n",
       "      <td>0.030938</td>\n",
       "      <td>0.376373</td>\n",
       "      <td>-0.692802</td>\n",
       "      <td>-0.571385</td>\n",
       "      <td>-0.965935</td>\n",
       "      <td>0.579370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.837509</td>\n",
       "      <td>-0.678885</td>\n",
       "      <td>0.135429</td>\n",
       "      <td>0.567828</td>\n",
       "      <td>-0.546941</td>\n",
       "      <td>0.849438</td>\n",
       "      <td>-0.152703</td>\n",
       "      <td>-1.030465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.837509</td>\n",
       "      <td>-1.529458</td>\n",
       "      <td>-1.118454</td>\n",
       "      <td>-0.197991</td>\n",
       "      <td>-0.076944</td>\n",
       "      <td>-1.480201</td>\n",
       "      <td>-0.419779</td>\n",
       "      <td>-0.945737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>-0.837509</td>\n",
       "      <td>0.353953</td>\n",
       "      <td>1.702782</td>\n",
       "      <td>0.440191</td>\n",
       "      <td>0.441673</td>\n",
       "      <td>0.107026</td>\n",
       "      <td>-0.686855</td>\n",
       "      <td>1.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.061376</td>\n",
       "      <td>0.232442</td>\n",
       "      <td>-0.491513</td>\n",
       "      <td>-0.580900</td>\n",
       "      <td>1.179081</td>\n",
       "      <td>-0.571385</td>\n",
       "      <td>0.192396</td>\n",
       "      <td>-0.183183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>-0.238252</td>\n",
       "      <td>-0.162466</td>\n",
       "      <td>0.239919</td>\n",
       "      <td>-0.389446</td>\n",
       "      <td>0.158054</td>\n",
       "      <td>-0.724988</td>\n",
       "      <td>-1.067964</td>\n",
       "      <td>-0.776281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>-0.837509</td>\n",
       "      <td>-1.013039</td>\n",
       "      <td>-2.058866</td>\n",
       "      <td>1.333647</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>2.948674</td>\n",
       "      <td>0.099369</td>\n",
       "      <td>-0.606824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.361005</td>\n",
       "      <td>-0.770018</td>\n",
       "      <td>0.239919</td>\n",
       "      <td>-0.197991</td>\n",
       "      <td>-0.149875</td>\n",
       "      <td>0.209428</td>\n",
       "      <td>1.602798</td>\n",
       "      <td>0.833555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
       "0   -0.537881 -0.982661  1.075840  0.567828 -0.692802  0.196628 -0.512806   \n",
       "1    0.061376  0.748861  0.814615  0.376373  0.117537 -0.392182 -0.821894   \n",
       "2    1.859148 -0.314354  0.030938  0.376373 -0.692802 -0.571385 -0.965935   \n",
       "3   -0.837509 -0.678885  0.135429  0.567828 -0.546941  0.849438 -0.152703   \n",
       "4   -0.837509 -1.529458 -1.118454 -0.197991 -0.076944 -1.480201 -0.419779   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "532 -0.837509  0.353953  1.702782  0.440191  0.441673  0.107026 -0.686855   \n",
       "533  0.061376  0.232442 -0.491513 -0.580900  1.179081 -0.571385  0.192396   \n",
       "534 -0.238252 -0.162466  0.239919 -0.389446  0.158054 -0.724988 -1.067964   \n",
       "535 -0.837509 -1.013039 -2.058866  1.333647  0.109434  2.948674  0.099369   \n",
       "536  0.361005 -0.770018  0.239919 -0.197991 -0.149875  0.209428  1.602798   \n",
       "\n",
       "          age  \n",
       "0    0.748827  \n",
       "1   -0.522096  \n",
       "2    0.579370  \n",
       "3   -1.030465  \n",
       "4   -0.945737  \n",
       "..        ...  \n",
       "532  1.003011  \n",
       "533 -0.183183  \n",
       "534 -0.776281  \n",
       "535 -0.606824  \n",
       "536  0.833555  \n",
       "\n",
       "[537 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.292</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>85</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.189</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>38.6</td>\n",
       "      <td>0.412</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.323</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>102</td>\n",
       "      <td>28</td>\n",
       "      <td>140</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.234</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>231</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.527</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>15</td>\n",
       "      <td>105</td>\n",
       "      <td>26.3</td>\n",
       "      <td>0.107</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>99</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.496</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.997</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg  plas  pres  skin  insu  mass   pedi  age\n",
       "491     2    89    90    30     0  33.5  0.292   42\n",
       "69      4   146    85    27   100  28.9  0.189   27\n",
       "667    10   111    70    27     0  27.5  0.141   40\n",
       "566     1    99    72    30    18  38.6  0.412   21\n",
       "97      1    71    48    18    76  20.4  0.323   22\n",
       "..    ...   ...   ...   ...   ...   ...    ...  ...\n",
       "369     1   133   102    28   140  32.8  0.234   45\n",
       "320     4   129    60    12   231  27.5  0.527   31\n",
       "527     3   116    74    15   105  26.3  0.107   24\n",
       "125     1    88    30    42    99  55.0  0.496   26\n",
       "265     5    96    74    18    67  33.6  0.997   43\n",
       "\n",
       "[537 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar a distribuição da feature mass antes e após a transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(X_train['mass'])\n",
    "plt.show()\n",
    "sns.kdeplot(X_train_standard['mass'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual a diferença entre as distribuições antes e após a transformação?\n",
    "\n",
    "Qual o melhor transformador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos aplicar o transformador RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "train = robust_scaler.fit_transform(X_train)\n",
    "test = robust_scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(train, columns = X_train.columns)\n",
    "X_test = pd.DataFrame(test, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.159032</td>\n",
       "      <td>0.098823</td>\n",
       "      <td>-0.162011</td>\n",
       "      <td>-0.090549</td>\n",
       "      <td>0.319195</td>\n",
       "      <td>-0.004014</td>\n",
       "      <td>0.275450</td>\n",
       "      <td>0.244824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.668115</td>\n",
       "      <td>0.748857</td>\n",
       "      <td>1.197400</td>\n",
       "      <td>0.490128</td>\n",
       "      <td>0.950155</td>\n",
       "      <td>0.868850</td>\n",
       "      <td>0.929106</td>\n",
       "      <td>0.694909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-2.659091</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.338462</td>\n",
       "      <td>-3.555556</td>\n",
       "      <td>-0.796657</td>\n",
       "      <td>-0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.338462</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.350975</td>\n",
       "      <td>-0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.649025</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.863636</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>2.343750</td>\n",
       "      <td>6.169231</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>5.727019</td>\n",
       "      <td>3.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres        skin        insu        mass  \\\n",
       "count  537.000000  537.000000  537.000000  537.000000  537.000000  537.000000   \n",
       "mean     0.159032    0.098823   -0.162011   -0.090549    0.319195   -0.004014   \n",
       "std      0.668115    0.748857    1.197400    0.490128    0.950155    0.868850   \n",
       "min     -0.600000   -2.659091   -4.500000   -0.750000   -0.338462   -3.555556   \n",
       "25%     -0.400000   -0.409091   -0.500000   -0.750000   -0.338462   -0.500000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.600000    0.590909    0.500000    0.250000    0.661538    0.500000   \n",
       "max      2.800000    1.863636    3.125000    2.343750    6.169231    3.900000   \n",
       "\n",
       "             pedi         age  \n",
       "count  537.000000  537.000000  \n",
       "mean     0.275450    0.244824  \n",
       "std      0.929106    0.694909  \n",
       "min     -0.796657   -0.470588  \n",
       "25%     -0.350975   -0.294118  \n",
       "50%      0.000000    0.000000  \n",
       "75%      0.649025    0.705882  \n",
       "max      5.727019    3.058824  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "grid_reg_log = GridSearchCV(\n",
    "    estimator = reg_log,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'roc_auc',\n",
    "    refit = 100,\n",
    "    n_jobs = -1,\n",
    "    verbose = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             refit=100, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_reg_log.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'class_weight': None, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_reg_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = grid_reg_log.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = grid_reg_log.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = grid_reg_log.predict(X_train)\n",
    "y_pred_test = grid_reg_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8451176361040413, 0.8163314176245211)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# métrica no treino e test\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "roc_auc_train , roc_auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "tested_negative       0.93      0.75      0.83       179\n",
      "tested_positive       0.48      0.81      0.60        52\n",
      "\n",
      "       accuracy                           0.76       231\n",
      "      macro avg       0.71      0.78      0.72       231\n",
      "   weighted avg       0.83      0.76      0.78       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(estimator=KNeighborsClassifier(), random_state=10,\n",
       "              search_spaces={'metric': ['minkowski', 'chebyshev'],\n",
       "                             'n_neighbors': array([ 3,  5,  7,  9, 11, 13]),\n",
       "                             'p': array([1, 2, 3, 4]),\n",
       "                             'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier()\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    random_state=SEED, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# espaço de pesquisa de hiperparâmetros\n",
    "param_distributions_knn = {\n",
    "    'n_neighbors': np.arange(3, 15, 2),\n",
    "    'p': np.arange(1, 5),\n",
    "    'metric': ['minkowski', 'chebyshev'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Bayesian Search\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=clf_knn,\n",
    "    search_spaces=param_distributions_knn,\n",
    "    n_iter=50,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# treino\n",
    "bayes_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = bayes_search.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = bayes_search.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = bayes_search.predict(X_train)\n",
    "y_pred_test = bayes_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.7720306513409962)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# métrica no treino e test\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "roc_auc_train , roc_auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81       180\n",
      "           1       0.44      0.75      0.55        51\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.67      0.74      0.68       231\n",
      "weighted avg       0.81      0.73      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>-0.338462</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.200557</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>-0.344444</td>\n",
       "      <td>-0.487465</td>\n",
       "      <td>-0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>-0.338462</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.621170</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>-0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.045455</td>\n",
       "      <td>-1.5000</td>\n",
       "      <td>-0.18750</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>-1.288889</td>\n",
       "      <td>-0.114206</td>\n",
       "      <td>-0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.8750</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>-0.362117</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-0.7500</td>\n",
       "      <td>-0.37500</td>\n",
       "      <td>1.438462</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.454039</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-0.28125</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>-0.715877</td>\n",
       "      <td>-0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.659091</td>\n",
       "      <td>-2.6250</td>\n",
       "      <td>0.56250</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>0.367688</td>\n",
       "      <td>-0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.477273</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-0.18750</td>\n",
       "      <td>0.176923</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>1.763231</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg      plas    pres     skin      insu      mass      pedi       age\n",
       "0    -0.2 -0.636364  1.1250  0.18750 -0.338462  0.166667 -0.200557  0.764706\n",
       "1     0.2  0.659091  0.8125  0.09375  0.430769 -0.344444 -0.487465 -0.117647\n",
       "2     1.4 -0.136364 -0.1250  0.09375 -0.338462 -0.500000 -0.621170  0.647059\n",
       "3    -0.4 -0.409091  0.0000  0.18750 -0.200000  0.733333  0.133705 -0.470588\n",
       "4    -0.4 -1.045455 -1.5000 -0.18750  0.246154 -1.288889 -0.114206 -0.411765\n",
       "..    ...       ...     ...      ...       ...       ...       ...       ...\n",
       "532  -0.4  0.363636  1.8750  0.12500  0.738462  0.088889 -0.362117  0.941176\n",
       "533   0.2  0.272727 -0.7500 -0.37500  1.438462 -0.500000  0.454039  0.117647\n",
       "534   0.0 -0.022727  0.1250 -0.28125  0.469231 -0.633333 -0.715877 -0.294118\n",
       "535  -0.4 -0.659091 -2.6250  0.56250  0.423077  2.555556  0.367688 -0.176471\n",
       "536   0.4 -0.477273  0.1250 -0.18750  0.176923  0.177778  1.763231  0.823529\n",
       "\n",
       "[537 rows x 8 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de métricas\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "logist_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "logist_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402597402597403"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logist_model.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,  44],\n",
       "       [ 16,  43]], dtype=int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42570635726784867"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81       172\n",
      "           1       0.49      0.73      0.59        59\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.69      0.74      0.70       231\n",
      "weighted avg       0.79      0.74      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(random_state=145, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=145, ...)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x = xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predict_x, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       169\n",
      "           1       0.54      0.76      0.63        62\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.72      0.76      0.73       231\n",
      "weighted avg       0.80      0.76      0.77       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predict_x, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7489177489177489"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123,  37],\n",
       "       [ 21,  50]], dtype=int64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81       160\n",
      "           1       0.57      0.70      0.63        71\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.71      0.74      0.72       231\n",
      "weighted avg       0.77      0.75      0.76       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variáveis qualitativas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos trabalhar com outro dataset para ilustrar os conceitos para o tratamento de features qualitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic_reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que precisamos tratar adicionalmente algumas variáveis qualitativas. Pclass refere-se a classe que o passageiro viajou, embarked é o porto que o passageiro embarcou, sex o sexo do passageiro e survived é se o passageiro sobreviveu ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked   Age     Sex Pclass  Survived\n",
       "0        S  22.0    male    3rd         0\n",
       "1        C  38.0  female    1st         1\n",
       "2        S  26.0  female    3rd         1\n",
       "3        S  35.0  female    1st         1\n",
       "4        S  35.0    male    3rd         0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked    0\n",
       "Age         0\n",
       "Sex         0\n",
       "Pclass      0\n",
       "Survived    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos remover nan\n",
    "titanic.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos separar os dados em treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "X = titanic.drop(columns = ['Survived'])\n",
    "y = titanic.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já conhecemos o One-Hot-Encoder da função `pd.get_dummies()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se tivermos features com muitos níveis podemos incorrer no problema de alta dimensionalidade, o que pode ser um problema em termos de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     male\n",
       "736     0\n",
       "679     1\n",
       "772     0\n",
       "518     0\n",
       "541     0\n",
       "..    ...\n",
       "462     1\n",
       "399     0\n",
       "668     1\n",
       "156     0\n",
       "331     1\n",
       "\n",
       "[498 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cria uma dummy para o sexo feminino\n",
    "pd.get_dummies(X_train.Sex, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = X_train.select_dtypes(object).columns.tolist()\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop = 'first')\n",
    "X_train_cat = one_hot_encoder.fit_transform(X_train[cols_cat])\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns = one_hot_encoder.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_Q</th>\n",
       "      <th>x0_S</th>\n",
       "      <th>x1_male</th>\n",
       "      <th>x2_2nd</th>\n",
       "      <th>x2_3rd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0_Q  x0_S  x1_male  x2_2nd  x2_3rd\n",
       "0   0.0   1.0      0.0     0.0     1.0\n",
       "1   0.0   0.0      1.0     0.0     0.0\n",
       "2   0.0   1.0      0.0     1.0     0.0\n",
       "3   0.0   1.0      0.0     1.0     0.0\n",
       "4   0.0   1.0      0.0     0.0     1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas o processamento que fizemos para a coluna Pclass foi correto? Quando trabalharmos com features que sejam categóricas ordinais podemos usar o OrdinalEncoder. Para cada nível será atribuído um número, sendo que precisaremos estabelecer essa ordem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3rd', '1st', '2nd'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Pclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['1st', '2nd', '3rd']\n",
    "levels = np.array(levels).reshape(1, len(levels))\n",
    "levels = list(levels)\n",
    "ordinal_encoder = OrdinalEncoder(categories = levels)\n",
    "pclass = X_train.loc[:, ['Pclass']]\n",
    "pclass_ordinal = pd.DataFrame(ordinal_encoder.fit_transform(pclass), columns = ['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vejamos a distribuição de frequências:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAHeCAYAAACYBc3eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAf+UlEQVR4nO3dfbzmd13f+dcXAmwtY4EGpjEzEiyhCmvFOoIudY3lUWGxS9CKG7ASFzTYwgqVRyvaXYm1We221LoqSFxYWJGbqCDUFhRRVm2FyF3LTaRkScAjCCIgQ0Q0yXf/+P2OOZycyUxmzskZZp7Px+N6XNfv/vO7O+d9fa/vuc6YcwYAAGe7O+13AQAAcDoQjAEAIMEYAAAqwRgAACrBGAAAKsEYAAAqwRhOW2OMuT4u2OX1XrC57t3c1hjj+nUdF53g/BeOMT48xnjWGOMZY4x/erLbPsb637DW8/TdXO/pZIzxzWOMG8YYbxlj3G0X1/vC9dhdvlvrvCONMS5f63/hDtPuMsZ4xxjjNWOMc3Zpexet27t+N9Z3jG3syc8D4LMJxnAH2xIgbx5jfGodvmqM8dBts/7Y+vjkCazz9gSZT25Z9256wbrOjROc/+9V11XPqP519Z5drueUbH0Dse3xif2urWqM8UXVFdVXVP+x+tFdXP2vtJzLN+7iOv/CGOPua6C/1RupMcY/Wce/5RQ28caW+n9lh2n/tPrz6rFzzhtPYRu3y5b7fvPx0THGL48xjtxRNQDHtyvvloGT8u+rP6weVj22+sYxxuPnnD9XNed8+m5vcIxxlznnx6pdX/ec85/fzkV+t7qsurF6dPVLu13TLvqp6jPr60/vNMMY405Vc86b74iC5pzvq/7GOvjdu7zul1Qv2c11blv/p8YYr64uqR5XvWHL5Mevzy8+mXWv1/hrq9fuMO1OLdfbN8w5P3Uy698Fv9TyhvBrq6+vvnKM8cVzzo/sUz3AVnNODw+PO/BRXV/N6jHr8DnVS9dxf1R93jp+ro8L1uGnV/9f9actgfoNLcHohVvm3Xy8sLpgy/B3VR+sfn3r+C01bc53WfXe6hPV86u/tE6/fHO9Oyxzwbb9umgd/rzqB1sC8KdbWpK/c532D6p3V0erP6v+a/WPtqx7rLW8o7qhurb6F9V/cxvH9ZvW+f64enb1G2s9T98yzxOr/1x9at3P76/OOcb6th6/e+ww/Q3rtH9ZvaklcF2w7vePrLXcUL1181yvy92j+rl13/9L9T3rej6xfbtbltk8x5efyL5U377O/1stLcmfqH6/+tYty9/W+fms7VV/t3rbemz/vHp/9YOneB98Q7dc83dZx33xOu7G6q+dwHVy+Tr/z1dXrfvx7W27Xqu/2dKK/PG1/g9VP1HdteVau26d/29tWff71nFH1uFHV1e3fOLy/pZrbPNevWid9/rbcd+f2y3X18XruC+pXtlyr366ent132Pcb89e1/mn1Z+s+3fRlu09fj12n64+Vv129be3nM+3tFyff9xyjX7Tfv9s9PA4HR66UsA+m8vHuT+4Dt6rpQX5s4wx7t8ScD6/JbS8rvrC6ryWj4uvWWd9Uzt/hHxF9ZrqPx2nnH9e/WZLCHliSxg9WT9d/UB1n5bg/9bqAeu0+7YEjxdXL68OVT85xvjqdfo/rJ5XHV6nn1P9s47R/WM9Pi+v/npL+P+qth3HMcaTW8L+PVuC1E0tx+WfncC+/PAY49+uj6dum/ZPqo+s+/iZdRvf2xI4fmHdh1ds6TLwf1bf3BJW39xyjG6X27EvD1sfV1dfUD1vjPH567TbOj/bnV99tHpZ9TPVgeoHxhiX3N7at/jlljd492ppOa361vX5V+ecf9Dxr5NNf7/l3P9M9Qc7bOsLqnu3tNa+uPrL1VOq75lzzm5pnf6fqsYYX1ndr7pmzvnmMcYjqlet417Vciy+p/rJk9nxteX6a7eM+ugY46+13HuPWffhxS2h/Z7HWM39Wu7357dc8w+tfm6McWCM8Zdafk7ct/rZlk+nPr/lGFX939WXtVyfv1DdXP23J7MvcKbRlQJOD+/f8vo+O0y/y/r8weoV1bvnnBtjjDvPOW8aY3x9S2vTa+ecl9fSR3bL8o+dc/7aDuO3e/Kc81VjjIurX6ye0NIH+HYZY5zbLR+JP3zO+bZ1/OZ+/KuWFrgHtbSg/l5LKPu6lpatzfD5tDnni8YYX9bSevYdY4ynzTn/dNsmL2n5efZrc87HrH9UtVEd3DLPZneDq7sllP6NlhD+g92279ry+v9taW3c9OI55xPW/bv3WsvNLW9Cbqre1RKCvmuM8Zut4at6/JzzN8cYb2sJy7fHie7Lx6r/fq3j0y2B8AHrH4nd1vnZ7v9pCf9/q/qrLZ9cHKn+TktY/ixjjMdXD9kcnjt0C5pz3jjGeHnLuX5cS3jbDNo/sz4f7zrZ9L7qoeubzMYYX7Vtc79VXTjnvHmM8Xkt/dl/eK3/R9b9+1+rb2l5U/MtW/a7bjneb2tp4X7TeiwuHWM8Zfu+Hccrtw3/u3Vfvqfl2L69pZX65nVfjvV7+jta3mBd0PKJwZ+0tEJ/acsnEXduOWe/2PLz4n1jjDuvy96lpaX51S2fyry3JYTDWU8whtPDfbe8vlVfwznnNWOMZ7X8gv7lqjHGe1p+Mb7zBNb/H0+wjs2W599dn8/d6dsOtvyCPZb7rc9/thm6quacf76+/Hfd0kq41b3X5wuOUc+dWlpg37ttufPX5/es27lxjHFdnx2MN9f597cte3CMcfd5231O7znn/MQxpm09tpvbuFO3hPtN928JLnfdWmtL94Dj2X68N7ez475sGb5m803EGOOGllbDu3f887Pdc1u6tmx37x3G1XJuL90y/PRjzPfiluN08dqifv+Wj/d/cZ1+vOtk09Xztv+Q7v7Vj68twVuv53tXzTnfO8b47eqr1z+C/eaWNzebLckXrM9/d31sGtUX3cZ2d/JLLd1s/qilO8Nr55xzjLF5Tq6eW/qp77RfY4y/2hJoz9th/feeSx/uf1g9q+UYNsbYqL6tpQvQk1vedPzcuswftZyHW73JgbONrhSwz9YWoWetgx9rhxC7BtEr5pzntoTof9nSQviP11luWp93vKfnnJ/ZafwOvmR9/uL1+aPrsjesw5sfwx/vY9fr1ue7jjEevDlyjHHOGOMe3RJ2vm6t+TWbs6zP12+rY/OPzG5uaTXc7ve3zrce0/ttm2dznY+ec47NR/VFxwnFx7P12G5u489aAsrmNu5afWPLR/B/trXWbt19YfNYt6Xbw/bjvbmd4+3L1lA1t7w+5vm51d4tNlu5v70lpD93c5GdZp5zfvu2unY053xTy5ucu7d07ah6xZzzhhO8TjYd7/r+8epvt3QruGgd3r6ezdbhf9UShH9tzrn5DSvXr8/fvW2//vqc80TemG71/DnnP55z/os552vWrhx1yzn5ys0/5KxjnpOvaQnFf9jSF/tuLZ8cbN2nF805z2/pRvK0lm4o/9s67TVzzgtb3qh9c0tL9RW3cz/gjKTFGPbPk8YYj27pA/qAlhDzXXPOP9lh3sPVm8YYv9HSorzZf/YT6/NmWPwHY4y/0tLidl233/PWmv7HdXjzI+3NVsVHjTGeXT3qtlYy5/zoGOMlLR/Xv36M8YstfSXf2/KR9adawtDlLX8Q9fBtq/jJlu4KPzbG+NqWj7xrCRXbu1HU0v/08urvrNs6t1t3SfmJ6jnVi8cYr2wJWkdajudFt7U/J2rO+YdjjKtaPop/0xjjdS2h42uqn5pzXr52H/i26iXr9G/aYR0bLUHmxWOMP60evJv7cpzz8707LPLh6q+0fGLx9S0hf7f8bMu5u/86vNlKe0PHv05O1GaL+0Nb3iA8eod5Xl7925ZzVbcE5VqO96Oq/2OM8d+1dEv5my3ndvsbsJP14uqZ1ZdXV69fV/cVLV0m3r5t3g+vz/du+duDL2o5Tp81zxjjDS3dr750HfeJ9flta3eaD7T8bNk6Dc5qWoxh/3xDS0vc3Vr+ov5hc/2qth18sqU/6cOq72xpBXpZt/xx3E+39Gk9vyW8fMVJ1vQDLX1S71a9qCXENuf81ZZ+sJ9uCUU/cawVbPGd1Q+1tJI+saXP6bXrx/WXtvxS/sqWX8g/v23Z51T/qKUl+HEtLcU/3NLydStzzveu872vJTy9vVu3vP9US8i4rqWV7FFrbf/XCezL7fGkln6rN7e0sD6spQ/p5teHfXfL/t6jJcz+0DHW8b6WkHZzyx98bbUb+7L1/Hxr6/k5xrzf0dKd5YEtf3j3vNuxnePZ+rVsf1C9vv6iW8fxrpMT9bSWfrf3b3kT+uPbZ5hzfry120FLIH/Flmmvabnu/3PLsf6mlvOya98Fvv6x4de0vKk9v6V//zktbwi2z/vbLS28H2/p2vHSbvnUZNPrWvpBP6mlj/a/75a/F/jVlk8sLm1pSX9DyzmGs9645VMcgL0xxriyeu7W/qws1r61v1798ZzzHvtaDMBZTosxsGfGGIfGGM9v6SN6sh+DA8AdQh9jYC/Nlv7Ks+VrzgDgtKUrBQAApCsFAABUgjEAAFSnSR/jc889d15wwQX7XQYn6eabb+5Od/IeC+5o7j3YH+69z21vectbPjrn3PE/d54WwfiCCy7ozW9+836XwUk6evRoBw4c2O8y4Kzj3oP94d773DbGeP+xpnm7AwAACcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUNU5+10AAHDmGWPsdwl75tChQ21sbOx3GXtmzrnfJewbLcYAAJBgDAAAlWAMAACVYAwAAJVgDAAAlWAMAACVYAwAAJVgDAAAlWAMAACVYAwAAJVgDAAAlWAMAADVCQTjMcbhMcavjzGuGWO8a4zxtHX85WOM3x9jvH19PGrLMt83xrh2jPGeMcYj9nIHAABgN5xzAvPcWD1jzvnWMcaB6i1jjNet0350zvmvt848xnhgdUn1oOoLql8dYzxgznnTbhYOAAC76bgtxnPOD80537q+PlpdU51/G4tcXL1szvmZOed11bXVQ3ajWAAA2Csn0mL8F8YYF1RfXr2pelj11DHGE6o3t7Qqf7wlNL9xy2Ib7RCkxxiXVZdVHT58uKNHj55M/ZwGbrjhhv0uAc5K7j1OZ4cOHdrvEvbMwYMH97uEPXU2Z7ITDsZjjLtXv1A9fc75yTHGc6sfqub6/OzqidXYYfF5qxFzXlldWXXkyJF54MCB2189pw3nD/aHe4/T1cbGxn6XsKfO5P07m3+unNC3Uowx7tISin92zvmKqjnnh+ecN805b65+ulu6S2xUh7csfqj64O6VDAAAu+9EvpViVM+vrplz/pst48/bMts3Vu9cX7+6umSMcbcxxv2qC6urd69kAADYfSfSleJh1bdV7xhjvH0d9/3V48YYD27pJnF99eSqOee7xhhXVe9u+UaLp/hGCgAATnfHDcZzzt9q537D/+E2lrmiuuIU6gIAgDuU/3wHAAAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFCdQDAeYxweY/z6GOOaMca7xhhPW8ffa4zxujHGe9fne25Z5vvGGNeOMd4zxnjEXu4AAADshhNpMb6xesac80uqr6qeMsZ4YPXM6vVzzgur16/DrdMuqR5UPbJ6zhjjzntRPAAA7JbjBuM554fmnG9dXx+trqnOry6uXrTO9qLqMevri6uXzTk/M+e8rrq2esgu1w0AALvqdvUxHmNcUH159abq4JzzQ7WE5+o+62znV7+3ZbGNdRwAAJy2zjnRGccYd69+oXr6nPOTY4xjzrrDuLnD+i6rLqs6fPhwR48ePdFSOM3ccMMN+10CnJXce5zODh06tN8l7JmDBw/udwl76mzOZCcUjMcYd2kJxT8753zFOvrDY4zz5pwfGmOcV31kHb9RHd6y+KHqg9vXOee8srqy6siRI/PAgQMnuQucDpw/2B/uPU5XGxsb+13CnjqT9+9s/rlyIt9KMarnV9fMOf/Nlkmvri5dX19avWrL+EvGGHcbY9yvurC6evdKBgCA3XciLcYPq76tescY4+3ruO+vfqS6aozxpOoD1WOr5pzvGmNcVb275RstnjLnvGm3CwcAgN103GA85/ytdu43XPXwYyxzRXXFKdQFAAB3KP/5DgAAEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKA6gWA8xnjBGOMjY4x3bhl3+Rjj98cYb18fj9oy7fvGGNeOMd4zxnjEXhUOAAC76URajF9YPXKH8T8653zw+vgPVWOMB1aXVA9al3nOGOPOu1UsAADsleMG4znnb1QfO8H1XVy9bM75mTnnddW11UNOoT4AALhDnHMKyz51jPGE6s3VM+acH6/Or964ZZ6NddytjDEuqy6rOnz4cEePHj2FUthPN9xww36XAGcl9x6ns0OHDu13CXvm4MGD+13CnjqbM9nJBuPnVj9UzfX52dUTq7HDvHOnFcw5r6yurDpy5Mg8cODASZbC6cD5g/3h3uN0tbGxsd8l7Kkzef/O5p8rJ/WtFHPOD885b5pz3lz9dLd0l9ioDm+Z9VD1wVMrEQAA9t5JBeMxxnlbBr+x2vzGildXl4wx7jbGuF91YXX1qZUIAAB777hdKcYYL60uqs4dY2xUz6ouGmM8uKWbxPXVk6vmnO8aY1xVvbu6sXrKnPOmPakcAAB20XGD8ZzzcTuMfv5tzH9FdcWpFAUAAHc0//kOAAASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgqnP2u4CzwRhjv0vYU4cOHWpjY2O/y9gzc879LgEAuANoMQYAgARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKjqnP0uAGCvjDH2u4Q9dejQoTY2Nva7jD0z59zvEoCzjBZjAABIMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCA6gSC8RjjBWOMj4wx3rll3L3GGK8bY7x3fb7nlmnfN8a4dozxnjHGI/aqcAAA2E0n0mL8wuqR28Y9s3r9nPPC6vXrcGOMB1aXVA9al3nOGOPOu1YtAADskeMG4znnb1Qf2zb64upF6+sXVY/ZMv5lc87PzDmvq66tHrI7pQIAwN455ySXOzjn/FDVnPNDY4z7rOPPr964Zb6NddytjDEuqy6rOnz4cEePHj3JUk5/hw4d2u8S9tTBgwf3u4Q9dSZfm2c6997nNvfe57Yz+f5z7525TjYYH8vYYdzcacY555XVlVVHjhyZBw4c2OVSTh8bGxv7XcKeO5P38Uy+Ns90Z/J1uelM3kf33ue2M/narDN7/87me+9kv5Xiw2OM86rW54+s4zeqw1vmO1R98OTLAwCAO8bJBuNXV5eury+tXrVl/CVjjLuNMe5XXVhdfWolAgDA3jtuV4oxxkuri6pzxxgb1bOqH6muGmM8qfpA9diqOee7xhhXVe+ubqyeMue8aY9qBwCAXXPcYDznfNwxJj38GPNfUV1xKkUBAMAdzX++AwCABGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACoBGMAAKgEYwAAqARjAACo6pxTWXiMcX11tLqpunHOeWSMca/q5dUF1fXVt8w5P35qZQIAwN7ajRbjr5tzPnjOeWQdfmb1+jnnhdXr12EAADit7UVXiourF62vX1Q9Zg+2AQAAu+pUg/GsfmWM8ZYxxmXruINzzg9Vrc/3OcVtAADAnjulPsbVw+acHxxj3Kd63Rjjd090wTVIX1Z1+PDhjh49eoqlnL4OHTq03yXsqYMHD+53CXvqTL42z3Tuvc9t7r3PbWfy/efeO3OdUjCec35wff7IGOOV1UOqD48xzptzfmiMcV71kWMse2V1ZdWRI0fmgQMHTqWU09rGxsZ+l7DnzuR9PJOvzTPdmXxdbjqT99G997ntTL4268zev7P53jvprhRjjL88xjiw+br6+uqd1aurS9fZLq1edapFAgDAXjuVFuOD1SvHGJvrecmc87VjjN+prhpjPKn6QPXYUy8TAAD21kkH4znn+6ov22H8H1UPP5WiAADgjuY/3wEAQIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUexiMxxiPHGO8Z4xx7RjjmXu1HQAA2A17EozHGHeufrL6H6oHVo8bYzxwL7YFAAC7Ya9ajB9SXTvnfN+c88+ql1UX79G2AADglJ2zR+s9v/q9LcMb1UO3zjDGuKy6bB381BjjPXtUC3tsY2Pj3Oqj+13HXhlj7HcJsCP3HuwP997nvPsea8JeBeOdjuj8rIE5r6yu3KPtcwcaY7x5znlkv+uAs417D/aHe+/MtVddKTaqw1uGD1Uf3KNtAQDAKdurYPw71YVjjPuNMe5aXVK9eo+2BQAAp2xPulLMOW8cYzy1+uXqztUL5pzv2ottcVrQJQb2h3sP9od77ww15pzHnwsAAM5w/vMdAAAkGAMAQCUYAwBAtXffY8wZbIzxxS3/yfD8lu+n/mD16jnnNftaGADsgfX33vnVm+acn9oy/pFzztfuX2XsNi3G3C5jjO9t+Rffo7q65av5RvXSMcYz97M2OFuNMf7n/a4BzlRjjO+uXlX9L9U7xxgXb5n8v+9PVewV30rB7TLG+K/Vg+acf75t/F2rd805L9yfyuDsNcb4wJzzC/e7DjgTjTHeUX31nPNTY4wLqp+vfmbO+WNjjLfNOb98fytkN+lKwe11c/UF1fu3jT9vnQbsgTHGfznWpOrgHVkLnGXuvNl9Ys55/Rjjournxxj3bbn/OIMIxtxeT69eP8Z4b/V767gvrO5fPXW/ioKzwMHqEdXHt40f1X+648uBs8YfjDEePOd8e9Xacvz3qhdUX7qvlbHrBGNulznna8cYD6ge0vKHCKPaqH5nznnTvhYHZ7Zfqu6++ct5qzHGG+7wauDs8YTqxq0j5pw3Vk8YYzxvf0pir+hjDAAA+VYKAACoBGMAAKgEYwAAqARjAACoBGMAAKjq/wfg3O3sRbWkDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pclass_ordinal.Pclass.astype(int).value_counts().sort_index().plot(kind = 'bar', color ='k', figsize = (12, 8))\n",
    "plt.title('Distribuição de Frequência - Variável Pclass', weight = 'bold')\n",
    "plt.grid(alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>S</td>\n",
       "      <td>48.0</td>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>C</td>\n",
       "      <td>36.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>S</td>\n",
       "      <td>57.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>S</td>\n",
       "      <td>36.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>S</td>\n",
       "      <td>9.0</td>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>S</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>S</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>S</td>\n",
       "      <td>43.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Q</td>\n",
       "      <td>16.0</td>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>S</td>\n",
       "      <td>45.5</td>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked   Age     Sex Pclass\n",
       "736        S  48.0  female    3rd\n",
       "679        C  36.0    male    1st\n",
       "772        S  57.0  female    2nd\n",
       "518        S  36.0  female    2nd\n",
       "541        S   9.0  female    3rd\n",
       "..       ...   ...     ...    ...\n",
       "462        S  47.0    male    1st\n",
       "399        S  28.0  female    2nd\n",
       "668        S  43.0    male    3rd\n",
       "156        Q  16.0  female    3rd\n",
       "331        S  45.5    male    1st\n",
       "\n",
       "[498 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Referências**\n",
    "\n",
    "\n",
    "[Top 10 model performance metrics for classification ML models](https://towardsdatascience.com/top-10-model-evaluation-metrics-for-classification-ml-models-a0a0f1d51b9)\n",
    "\n",
    "[A Practical Guide to Seven Essential Performance Metrics for Classification using Scikit-Learn](https://towardsdatascience.com/a-practical-guide-to-seven-essential-performance-metrics-for-classification-using-scikit-learn-2de0e0a8a040)\n",
    "\n",
    "[Popular Evaluation Metrics for Classification with Code](https://towardsdatascience.com/popular-evaluation-metrics-for-classification-with-code-580fa0d4eb20)\n",
    "\n",
    "\n",
    "[20 Popular Machine Learning Metrics. Part 1: Classification & Regression Evaluation Metrics](https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
