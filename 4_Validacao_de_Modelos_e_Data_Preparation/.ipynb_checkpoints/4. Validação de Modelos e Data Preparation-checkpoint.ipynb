{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bootcamp de Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Validação de modelos e Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir o processo de Data Preparation como o fluxo de transformação de dados brutos em dados finais mais apropriados para a criação de modelos de Machine Learning. Algumas tarefas comuns neste processo envolvem, limpeza de dados, seleção de features, transformação de dados, criação de variáveis, etc. \n",
    "\n",
    "Grande parte do trabalho do Cientista de Dados reside em criar boas variáveis e assegurar a qualidade dos dados.\n",
    "\n",
    "\n",
    "**Etapas do processo de Data Preparation**\n",
    "\n",
    "* Data Cleaning\n",
    "    * Identificação de redundâncias e inconsistências\n",
    "        * Exemplos: Valor monetário negativo (pode ou não fazer sentido a depender do contexto); Idade acima de 300 anos ou idade negativa, dentre outros exemplos.\n",
    "    * Identificação/tratamento de outliers\n",
    "        * Exemplos: cliente com 190 anos de idade\n",
    "    * Identificação/tratamento de missing (marcação e imputação)\n",
    "    \n",
    "* Feature Selection\n",
    "    * Como selecionar as melhores features no conjunto de 100, 500, 1000, ou 10000 features? \n",
    "    * Quais questõs poderíamos pensar de um modelo com muitas variáveis?\n",
    "    \n",
    "* Data Transforms\n",
    "    * Discretization Transform\n",
    "        * Encode de uma variável numérica em uma variável ordinal\n",
    "    * Ordinal Transform\n",
    "        * Encode de uma variável categórica em uma variável int\n",
    "    * One Hot Transform\n",
    "        * Encode de uma variável categórica em variável binária\n",
    "    * Normalization Transform\n",
    "        * Altera a escala da variável para um range entre 0 e 1\n",
    "    * Standardization Transform\n",
    "        * Distribuição Normal padrão\n",
    "    * Power Transform\n",
    "        * Altera a distribuição de uma variável de modo a aproximar para uma normal\n",
    "        \n",
    "* Feature Engineering\n",
    "    * Adicionar variáveis externas\n",
    "        * Exemplo: inserir variáveis macroeconômicas, sócioeconômicas, etc.\n",
    "    * Adicionar novas variáveis a partir da dimensão temporal\n",
    "    * Adicionar flag\n",
    "    * Aplicar transformações (mínimo, máximo, média, mediana, desvio padrão, amplitude, etc.)\n",
    "    * Indicadores\n",
    "\n",
    "* Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, podemos resumir:\n",
    "\n",
    "* Alterar a escala da variável: RobustScaler, StandardScaler, MinMaxScaler.\n",
    "* Alterar a distribuição: Power Transform, Quantile Transform, Discretization\n",
    "* Encode de variável categórica\n",
    "    * Nominal: One Hot Encode\n",
    "    * Ordinal: Label Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipos de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis podem ser mensuradas em quatro escalas distintas. As variáveis quantitativas podem ser classificadas em discretas ou contínuas, enquanto que as variáveis qualitativas podem ser agrupadas em nominais ou ordinais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Variáveis qualitativas\n",
    "* variável nominal: não há qualquer ordenação na distribuição dos dados (ou dentre as categorias).\n",
    "    * Exemplos: gênero, cor dos olhos,região de procedência, etc.\n",
    "* variável ordinal: há uma ordem dentre as categorias (escala ordinal).\n",
    "    * Exemplos: escolaridade/grau de instrução, hierarquia militar, estágio de uma doença, mês de observação, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Variáveis quantitativas\n",
    "* variável discreta: seus valores podem ser oriundos de um conjunto finito ou enumerável (contagem).\n",
    "    * Exemplos: número de filhos, número de refeições em um dia, etc.\n",
    "* variável contínua: seus valores pertencem a um intervalo (mensuração).\n",
    "    * Exemplos: temperatura, preço de uma ação, altura, peso, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis quantitativas\n",
    "\n",
    "MinMaxScaler\n",
    "* O range de valores é alterado para $[0,1]$\n",
    "* A distribuição dos dados não se altera\n",
    "* Técnica sensível à outliers\n",
    "\n",
    "Fórmula de cálculo:\n",
    "\n",
    "$$X_{\\text{new}} = \\dfrac{X_i-\\text{min}(X)}{\\text{max}(X)-\\text{min}(X)}$$\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/416/1*vEqbUwYneOkRQXCdPU0n9g.png\" height=200 width=200/>\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)\n",
    "\n",
    "\n",
    "MaxAbsScaler\n",
    "\n",
    "Fórmula de cálculo:\n",
    "\n",
    "$$X_{\\text{new}} = \\dfrac{X_i}{|X_{max}|}$$\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler)\n",
    "\n",
    "Padronização (Standard Scaler)\n",
    "* Os dados ficam centrados em 0, com dispersão igual a 1\n",
    "* Não obteremos uma distribuição normal (caso a distribuição original não for Normal; se a distribuição original for uma Normal teremos então uma distribuição Normal padrão)\n",
    "* Técnica sensível à outliers\n",
    "\n",
    "Fórmula de cálculo: \n",
    "\n",
    "$$Z = \\dfrac{X-\\mu}{\\sigma}$$\n",
    "\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n",
    "\n",
    "\n",
    "RobustScaler\n",
    "* Robusto à outlier, sendo similar ao MinMax, mas usa os quartis Q1 e Q3 para o scaling\n",
    "\n",
    "Fórmula de cálculo:\n",
    "\n",
    "$$\\dfrac{x_i-Q_1(X)}{Q_3(X)-Q_1(X)}$$\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler)\n",
    "\n",
    "PowerTransformer\n",
    "* Implementa as transformações de Yeo-Johnson (para valores positivos e negativos) e Box-Cox (para valores estritamente positivos).\n",
    "\n",
    "Implementação no sklearn: [sklearn.preprocessing.PowerTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer)\n",
    "\n",
    "#### Variáveis qualitativas\n",
    "\n",
    "\n",
    "One-Hot-Encoder\n",
    "* Usado para criar dummies\n",
    "* Igual ao método do Pandas `pd.get_dummies()`, mas podemos usar o Sklearn por sua integração com as Pipelines\n",
    "* Se a variável tiver muitas categoricas, teremos muitas colunas criadas (alta dimensionalidade)\n",
    "\n",
    "<img src=\"https://i.imgur.com/TW5m0aJ.png\" height=700 width=700/>\n",
    "\n",
    "Implementação no Pandas: [pd.get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n",
    "Implementação no sklearn: []()\n",
    "\n",
    "\n",
    "Ordinal-Encoder\n",
    "* Usado para variáveis categóricas ordinais (nível de satisfação do usuário em uma escala de 1 a 5, em que 5 representa a satisfação máxima)\n",
    "\n",
    "Frequency-Encoder\n",
    "* Aplicação prática: coluna com muitos níveis/categorias ou se não houver grau ordinal\n",
    "* Cada nível da classe será substituído por sua frequência\n",
    "\n",
    "\n",
    "LabelEncoder\n",
    "* Encode para os labels da variável target, com 0 a n_classes-1\n",
    "* Deve ser usado para a variável target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Revisão\n",
    "\n",
    "Bussab e Morettin (2010) ressaltam que tanto a média, quanto o desvio padrão podem não ser medidas suficientes para se representar um conjunto de dados, pois: \n",
    "* ambos são afetados de forma demasiada por valores extremos;\n",
    "* não podemos ter uma noção clara da simetria ou assimetria da distribuição dos dados.\n",
    "\n",
    "*  1º Quartil: 25% das observações abaixo e 75% das observações acima\n",
    "*  2º  Quartil: 50% das observações abaixo e 50% das observações acima\n",
    "*  3º Quartil: 75% das observações abaixo e 25% das observações acima\n",
    "\n",
    "Então os quartis dividem o conjunto de dados em quatro partes iguais.\n",
    "\n",
    "\n",
    "Um boxtpot (gráfico de caixa) fornece uma poderosa visualização da distribuição dos dados e valores discrepantes (outliers), sendo formados pelo primeiro quartil, segundo quartil (mediana), terceiro quartil e limites superior e inferior. \n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Missing handling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas técnicas de imputação de missing:\n",
    "* SimpleImputer\n",
    "    * Imputa pela média, mediana, constante, moda (pode alterar drasticamente a distribuição da variável)\n",
    "    \n",
    "* KNNImputer\n",
    "    * Usa a técnica k-Nearest Neighbors para preencher os valores ausentes\n",
    "* Baseada no negócio\n",
    "    * Média/mediana de um grupo específico (faixa de renda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Métricas de avaliação de modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação de modelos de classificação**\n",
    "\n",
    "Vamos começar definindo os seguintes conceitos:\n",
    "\n",
    "* Classe postiiva (1): Cliente Mau\n",
    "* Classe negativa (0): Cliente Bom\n",
    "\n",
    "Uma definição de negócio para cliente mau poderia ser, um cliente com mais de 30 dias de atraso em uma janela de três meses.\n",
    "\n",
    "* VP: modelo acertou em dizer que era um cliente mau;\n",
    "* VN: modelo acertou em dizer que era um cliente bom;\n",
    "* FN: modelo errou em dizer que era um cliente mau;\n",
    "* FP: modelo errou em dizer que era um cliente bom.\n",
    "\n",
    "\n",
    "Acurácia\n",
    "\n",
    "\n",
    "A fórmula de cálculo da acurácia é:\n",
    "\n",
    "$$\\dfrac{VP+VN}{VP+VN+FP+FN}$$\n",
    "\n",
    "Dos verdadeiros positivos (Cliente Mau) e verdadeiros negativos (Cliente Bom) quantos o modelo acertou no total?\n",
    "\n",
    "Ou ainda, quanto o modelo acertou das previsões totais?\n",
    "\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "\n",
    "Outros aspectos da acurácia:\n",
    "* Ideal para problemas de classificação com classes balanceadas\n",
    "\n",
    "Precisão\n",
    "\n",
    "A fórmula de cálculo da precisão é:\n",
    "\n",
    "$$\\dfrac{VP}{VP+FP}$$\n",
    "\n",
    "De tudo que o modelo classificou como Cliente Mau, quantos realmente eram? (ocorrência do evento, classe 1)\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "\n",
    "Recall\n",
    "\n",
    "\n",
    "De todos os exemplos que são Cliente Mau, quantos foram classificados corretamente pelo modelo?\n",
    "\n",
    "A fórmula de cálculo do recall é:\n",
    "$$\\dfrac{VP}{VP+FN} $$\n",
    "\n",
    "\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    "\n",
    "\n",
    "F1-Score\n",
    "\n",
    "* Média harmônica do Recall e Precision.\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "\n",
    "Matriz de confusão\n",
    "\n",
    "Implementação no sklearn: [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    "\n",
    "\n",
    "* Indica a qualidade do modelo e agrega informações do que o modelo acertou e errou.\n",
    "\n",
    "<img src = 'https://diegonogare.net/wp-content/uploads/2020/04/matrizConfusao-600x381.png' width=500 height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vejamos uma implementação no Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hands On!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from boruta import BorutaPy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeção e Limpeza de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proporção da variável target\n",
    "df_train.Survived.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype de cada coluna\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.00</td>\n",
       "      <td>223.5000</td>\n",
       "      <td>446.0000</td>\n",
       "      <td>668.5</td>\n",
       "      <td>891.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std   min       25%       50%    75%  \\\n",
       "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
       "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
       "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
       "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
       "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
       "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
       "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
       "\n",
       "                  max  \n",
       "PassengerId  891.0000  \n",
       "Survived       1.0000  \n",
       "Pclass         3.0000  \n",
       "Age           80.0000  \n",
       "SibSp          8.0000  \n",
       "Parch          6.0000  \n",
       "Fare         512.3292  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sumário estatístico\n",
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         2\n",
       "Sex              2\n",
       "Pclass           3\n",
       "Embarked         3\n",
       "SibSp            7\n",
       "Parch            7\n",
       "Age             88\n",
       "Cabin          147\n",
       "Fare           248\n",
       "Ticket         681\n",
       "PassengerId    891\n",
       "Name           891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantidade de valores únicos em cada coluna\n",
    "df_train.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linhas duplicadas\n",
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coluna constante\n",
    "df_train.columns[df_train.nunique() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapeia as colunas com baixa variância (técnica de seleção de variáveis)\n",
    "threshold = 0.001\n",
    "scaler = MinMaxScaler()\n",
    "# colunas numéricas\n",
    "num_cols = df_train.select_dtypes(include = [int, float])\n",
    "scaled_num_cols = scaler.fit_transform(num_cols)\n",
    "scaled_num_df = pd.DataFrame(scaled_num_cols,\n",
    "                             columns = num_cols.columns\n",
    "                            )\n",
    "\n",
    "low_variance_columns = list()\n",
    "for column in scaled_num_df:\n",
    "    column_variance = scaled_num_df[column].var()\n",
    "    if column_variance < threshold:\n",
    "        low_variance_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para o threshold definido não identificamos nenhuma coluna com baixa variância\n",
    "low_variance_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Tarefa: transforme o código anterior em uma função.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0.00\n",
       "Survived        0.00\n",
       "Pclass          0.00\n",
       "Name            0.00\n",
       "Sex             0.00\n",
       "SibSp           0.00\n",
       "Parch           0.00\n",
       "Ticket          0.00\n",
       "Fare            0.00\n",
       "Embarked        0.22\n",
       "Age            19.87\n",
       "Cabin          77.10\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifica missing values\n",
    "(df_train.isna().sum()/df_train.shape[0] * 100).round(2).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos três colunas com missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder vamos separar os dados em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 999999\n",
    "train, test = train_test_split(\n",
    "                df_train,\n",
    "                test_size = 0.3,\n",
    "                random_state = SEED\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0.00\n",
       "Survived        0.00\n",
       "Pclass          0.00\n",
       "Name            0.00\n",
       "Sex             0.00\n",
       "SibSp           0.00\n",
       "Parch           0.00\n",
       "Ticket          0.00\n",
       "Fare            0.00\n",
       "Embarked        0.00\n",
       "Age            20.22\n",
       "Cabin          78.17\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.isna().sum()/train.shape[0] * 100).round(2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nan(df):\n",
    "    # imputa os valores ausentes pela moda\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode().squeeze())\n",
    "    # Se possui Cabine 1, 0 caso contrário\n",
    "    df['Cabin'] = np.where(df.Cabin.isna(), 0, 1)\n",
    "    # imputa os valores ausentes de idade pela categoria de Sexo e Sobrevivência\n",
    "    df['category'] = df['Sex'] + '-' + df['Pclass'].astype(str)\n",
    "    categories = dict()\n",
    "    for i in df.category.unique():\n",
    "        filtered_data = df.loc[df.category == i]\n",
    "        median = filtered_data.Age.median()\n",
    "        categories[i] = median\n",
    "\n",
    "    nan_values = df.Age.isna()\n",
    "    df.loc[nan_values, 'Age'] = df.loc[nan_values, 'category'].map(categories)\n",
    "    df = df.drop(columns = 'category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clean_nan(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop de colunas que não serão utilizadas\n",
    "train.drop(columns = ['PassengerId', 'Name', 'Ticket'], inplace = True)\n",
    "test.drop(columns = ['PassengerId', 'Name', 'Ticket'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_vars(df):\n",
    "    df['Age_groups'] = pd.cut(df.Age, 5, labels = False)\n",
    "    df['Size'] = df.eval('SibSp+Parch')\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = new_vars(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clean_nan(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = new_vars(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns = ['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass          int64\n",
       "Age           float64\n",
       "SibSp           int64\n",
       "Parch           int64\n",
       "Fare          float64\n",
       "Cabin           int32\n",
       "Age_groups      int64\n",
       "Size            int64\n",
       "Sex_male        uint8\n",
       "Embarked_Q      uint8\n",
       "Embarked_S      uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state = SEED)\n",
    "reg_log = LogisticRegression()\n",
    "# validação cruzada regressão logística\n",
    "cross_val_reg_log = cross_validate(estimator = reg_log,\n",
    "                                   X = X_train,\n",
    "                                   y = y_train,\n",
    "                                   scoring = 'roc_auc',\n",
    "                                   cv = cv,\n",
    "                                   return_train_score = True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.86985809896708, 0.8579079842463301)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_reg_log['train_score'].mean(), cross_val_reg_log['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "clf_reg_log = RandomizedSearchCV(\n",
    "    estimator = reg_log,\n",
    "    param_distributions = param_grid,\n",
    "    scoring = 'roc_auc',\n",
    "    random_state = SEED,\n",
    "    n_iter = 100,\n",
    "    n_jobs = -1,\n",
    "    verbose = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1, 0.5, 1],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                    'none']},\n",
       "                   random_state=999999, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_reg_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'class_weight': None, 'C': 0.5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melhores hiperparâmetros\n",
    "clf_reg_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = clf_reg_log.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = clf_reg_log.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métrica no treino e test\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8680596047942988, 0.8223608850304455)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train , roc_auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Age_groups</th>\n",
       "      <th>Size</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.272388</td>\n",
       "      <td>29.274254</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.369403</td>\n",
       "      <td>33.043485</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>1.570896</td>\n",
       "      <td>0.847015</td>\n",
       "      <td>0.660448</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.727612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.859221</td>\n",
       "      <td>13.196090</td>\n",
       "      <td>0.888684</td>\n",
       "      <td>0.740556</td>\n",
       "      <td>57.040359</td>\n",
       "      <td>0.435960</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>1.377627</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>0.275015</td>\n",
       "      <td>0.446021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.772900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age       SibSp       Parch        Fare       Cabin  \\\n",
       "count  268.000000  268.000000  268.000000  268.000000  268.000000  268.000000   \n",
       "mean     2.272388   29.274254    0.477612    0.369403   33.043485    0.253731   \n",
       "std      0.859221   13.196090    0.888684    0.740556   57.040359    0.435960   \n",
       "min      1.000000    0.420000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   21.000000    0.000000    0.000000    7.925000    0.000000   \n",
       "50%      3.000000   27.000000    0.000000    0.000000   14.772900    0.000000   \n",
       "75%      3.000000   36.000000    1.000000    0.000000   33.125000    1.000000   \n",
       "max      3.000000   71.000000    5.000000    5.000000  512.329200    1.000000   \n",
       "\n",
       "       Age_groups        Size    Sex_male  Embarked_Q  Embarked_S  \n",
       "count  268.000000  268.000000  268.000000  268.000000  268.000000  \n",
       "mean     1.570896    0.847015    0.660448    0.082090    0.727612  \n",
       "std      0.931458    1.377627    0.474443    0.275015    0.446021  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      1.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    1.000000    0.000000    1.000000  \n",
       "75%      2.000000    1.000000    1.000000    0.000000    1.000000  \n",
       "max      4.000000    7.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva modelo\n",
    "pickle.dump(clf_reg_log, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Homework**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como parte dos estudos extra-classe analise as possibilidades de pré-processamento que foram aplicadas no exemplo a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcategory_encoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TargetEncoder\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from pandas_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(diabetes, title='Profiling Diabets', html={'style':{'full_width':True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra o relatório\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva o relatório\n",
    "profile.to_file(output_file=\"dataframe_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.drop(columns = 'class')\n",
    "y = diabetes['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.3,\n",
    "    random_state = SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando as distribuições\n",
    "sns.histplot(X_train['age'])\n",
    "plt.show()\n",
    "sns.histplot(X_train['mass'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora usaremos o scikit-learn para aplicar o MinMaxScaler, RobustScaler e StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora precisamos usar os métodos `fit()` e `transform()`. O `fit()` irá realizar a extração do que precisa para realizar a transformação, no caso do MinMax, equivale à extrair os valores mínimo e máximo. Em seguida, usamos o método `transform()` para realizar a transformação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos aplicar o MinMax na features `mass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.mass.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler.fit(X_train[['mass']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler.transform(X_train[['mass']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar também o método `fit_transform()` para realizar a extração dos parâmetros e aplicar a transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_new = min_max_scaler.fit_transform(X_train[['mass']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novos valores máximo e mínimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_new.min(), mass_new.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_new = pd.DataFrame(mass_new, columns = ['mass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos aplicar o StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplica a transformação em todo o conjunto de dados\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standard = standard_scaler.fit_transform(X_train)\n",
    "X_train_standard = pd.DataFrame(X_train_standard, columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standard.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar a distribuição da feature mass antes e após a transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(X_train['mass'])\n",
    "plt.show()\n",
    "sns.kdeplot(X_train_standard['mass'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual a diferença entre as distribuições antes e após a transformação?\n",
    "\n",
    "Qual o melhor transformador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos aplicar o transformador RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "X_train_robust = robust_scaler.fit_transform(X_train)\n",
    "X_train_robust = pd.DataFrame(X_train_robust, columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variáveis qualitativas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos trabalhar com outro dataset para ilustrar os conceitos para o tratamento de features qualitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic_reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que precisamos tratar adicionalmente algumas variáveis qualitativas. Pclass refere-se a classe que o passageiro viajou, embarked é o porto que o passageiro embarcou, sex o sexo do passageiro e survived é se o passageiro sobreviveu ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked      2\n",
       "Age         177\n",
       "Sex           0\n",
       "Pclass        0\n",
       "Survived      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos remover nan\n",
    "titanic.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos separar os dados em treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "X = titanic.drop(columns = ['Survived'])\n",
    "y = titanic.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já conhecemos o One-Hot-Encoder da função `pd.get_dummies()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se tivermos features com muitos níveis podemos incorrer no problema de alta dimensionalidade, o que pode ser um problema em termos de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     male\n",
       "736     0\n",
       "679     1\n",
       "772     0\n",
       "518     0\n",
       "541     0\n",
       "..    ...\n",
       "462     1\n",
       "399     0\n",
       "668     1\n",
       "156     0\n",
       "331     1\n",
       "\n",
       "[498 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cria uma dummy para o sexo feminino\n",
    "pd.get_dummies(X_train.Sex, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = X_train.select_dtypes(object).columns.tolist()\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop = 'first')\n",
    "X_train_cat = one_hot_encoder.fit_transform(X_train[cols_cat])\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns = one_hot_encoder.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_Q</th>\n",
       "      <th>x0_S</th>\n",
       "      <th>x1_male</th>\n",
       "      <th>x2_2nd</th>\n",
       "      <th>x2_3rd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0_Q  x0_S  x1_male  x2_2nd  x2_3rd\n",
       "0   0.0   1.0      0.0     0.0     1.0\n",
       "1   0.0   0.0      1.0     0.0     0.0\n",
       "2   0.0   1.0      0.0     1.0     0.0\n",
       "3   0.0   1.0      0.0     1.0     0.0\n",
       "4   0.0   1.0      0.0     0.0     1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas o processamento que fizemos para a coluna Pclass foi correto? Quando trabalharmos com features que sejam categóricas ordinais podemos usar o OrdinalEncoder. Para cada nível será atribuído um número, sendo que precisaremos estabelecer essa ordem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3rd', '1st', '2nd'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Pclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['1st', '2nd', '3rd']\n",
    "levels = np.array(levels).reshape(1, len(levels))\n",
    "levels = list(levels)\n",
    "ordinal_encoder = OrdinalEncoder(categories = levels)\n",
    "pclass = X_train.loc[:, ['Pclass']]\n",
    "pclass_ordinal = pd.DataFrame(ordinal_encoder.fit_transform(pclass), columns = ['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vejamos a distribuição de frequências:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pclass_ordinal.Pclass.astype(int).value_counts().sort_index().plot(kind = 'bar', color ='k', figsize = (12, 8))\n",
    "plt.title('Distribuição de Frequência - Variável Pclass', weight = 'bold')\n",
    "plt.grid(alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>S</td>\n",
       "      <td>48.0</td>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>C</td>\n",
       "      <td>36.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>S</td>\n",
       "      <td>57.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>S</td>\n",
       "      <td>36.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>S</td>\n",
       "      <td>9.0</td>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>S</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>S</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>S</td>\n",
       "      <td>43.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Q</td>\n",
       "      <td>16.0</td>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>S</td>\n",
       "      <td>45.5</td>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked   Age     Sex Pclass\n",
       "736        S  48.0  female    3rd\n",
       "679        C  36.0    male    1st\n",
       "772        S  57.0  female    2nd\n",
       "518        S  36.0  female    2nd\n",
       "541        S   9.0  female    3rd\n",
       "..       ...   ...     ...    ...\n",
       "462        S  47.0    male    1st\n",
       "399        S  28.0  female    2nd\n",
       "668        S  43.0    male    3rd\n",
       "156        Q  16.0  female    3rd\n",
       "331        S  45.5    male    1st\n",
       "\n",
       "[498 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Referências**\n",
    "\n",
    "\n",
    "[Top 10 model performance metrics for classification ML models](https://towardsdatascience.com/top-10-model-evaluation-metrics-for-classification-ml-models-a0a0f1d51b9)\n",
    "\n",
    "[A Practical Guide to Seven Essential Performance Metrics for Classification using Scikit-Learn](https://towardsdatascience.com/a-practical-guide-to-seven-essential-performance-metrics-for-classification-using-scikit-learn-2de0e0a8a040)\n",
    "\n",
    "[Popular Evaluation Metrics for Classification with Code](https://towardsdatascience.com/popular-evaluation-metrics-for-classification-with-code-580fa0d4eb20)\n",
    "\n",
    "\n",
    "[20 Popular Machine Learning Metrics. Part 1: Classification & Regression Evaluation Metrics](https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
